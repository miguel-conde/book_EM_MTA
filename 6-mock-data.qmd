# Mock data generation

La idea es generar un mundo sintÃ©tico donde conocemos la **verdad**:

-   Features por HCP (X_h)

-   ParÃ¡metros â€œrealesâ€ (\\beta\^\*)

-   Contribuciones latentes reales (z\^\*\_{h,b})

-   Ventas observadas por brick (y_b)

AsÃ­ luego podemos medir si EM recupera:

1.  (\\beta\^\*) (productividad estructural)

2.  (z\^\*\_{h,b}) (atribuciÃ³n)

3.  (y_b) (consistencia y calibraciÃ³n)

## 1ï¸âƒ£ DiseÃ±o de simulaciÃ³n (quÃ© queremos que sea realista)

### HCPs

-   **Especialidad** (categorÃ­a): GP / Cardio / Endo / â€¦

-   **Seniority** (numÃ©rica o ordinal)

-   **Visitas** (conteo; y pueden variar por brick)

-   Opcional: â€œpotencialâ€ (continua), â€œsegmentoâ€ (A/B/C)

### Bricks

-   ComposiciÃ³n heterogÃ©nea:

    -   bricks â€œdensosâ€ con muchos HCPs

    -   bricks â€œpequeÃ±osâ€ con pocos HCPs

    -   overlaps: un HCP puede estar en varios bricks

-   ExposiciÃ³n (w\_{h,b}):

    -   0 si no pertenece

    -   si pertenece: proporcional a visitas u otro proxy

### Verdadera productividad

-   Unidades (Poisson):\
    \[\
    \\lambda_h\^\* = \\exp(X_h\\beta\^\*)\
    \]

-   Luego:\
    \[\
    z\_{h,b}\^\* \\sim \\text{Poisson}(\\lambda_h\^\*, w\_{h,b})\
    \\quad;\\quad\
    y_b = \\sum_h z\_{h,b}\^\*\
    \]

## 2ï¸âƒ£ CÃ³digo Python: generador reutilizable (unidades / Poisson)

> Esto te deja un dataset listo para: entrenar EM, comparar contra ground truth, y hacer stress tests.

```         
import numpy as np import pandas as pd  def simulate_hcp_brick_poisson(     n_hcps=400,     n_bricks=80,     avg_bricks_per_hcp=2.5,     avg_hcps_per_brick=18,     seed=7, ):     rng = np.random.default_rng(seed)      # ----- (A) HCP features -----     specialties = np.array(["GP", "CARDIO", "ENDO", "ONCO", "PULMO"])     spec = rng.choice(specialties, size=n_hcps, p=[0.45, 0.18, 0.15, 0.12, 0.10])      seniority = rng.integers(0, 21, size=n_hcps)  # years (0..20)     potential = rng.lognormal(mean=0.0, sigma=0.6, size=n_hcps)  # positive continuous      # One-hot for specialty     spec_df = pd.get_dummies(spec, prefix="spec")     X = np.column_stack([         np.ones(n_hcps),                         # intercept         seniority / 10.0,                        # scaled         np.log1p(potential),                     # log feature         spec_df.to_numpy(),                      # dummies     ])     feature_names = (["intercept", "seniority_x0.1", "log1p_potential"]                      + list(spec_df.columns))      p = X.shape[1]      # ----- (B) True beta* (ground truth) -----     beta_true = np.zeros(p)     beta_true[0] = -0.3                    # intercept     beta_true[1] =  0.20                   # seniority helps     beta_true[2] =  0.55                   # potential helps      # Specialty effects (relative to baseline; here baseline is implicitly captured by intercept)     # Put mild lifts / penalties     for j, name in enumerate(feature_names):         if name == "spec_CARDIO":             beta_true[j] = 0.25         elif name == "spec_ONCO":             beta_true[j] = 0.35         elif name == "spec_PULMO":             beta_true[j] = 0.10         elif name == "spec_ENDO":             beta_true[j] = 0.15         # GP left at 0 shift (reference-ish), though with full one-hot it's not a strict reference.     # (With full one-hot + intercept, there is collinearity; in practice you drop one dummy.     # For simulation it's fine; for fitting, use a reference category or regularize.)      # True productivity per HCP     lambda_true = np.exp(X @ beta_true)      # ----- (C) Brick membership + exposure w_{h,b} -----     # Goal: heterogeneous bricks + overlaps.     # We'll assign each HCP to K bricks, K ~ Poisson(avg_bricks_per_hcp) truncated >=1     K = rng.poisson(lam=avg_bricks_per_hcp, size=n_hcps)     K = np.clip(K, 1, max(1, n_bricks // 2))      # Popularity of bricks (some bricks are "bigger")     brick_pop = rng.lognormal(mean=0.0, sigma=0.7, size=n_bricks)     brick_pop = brick_pop / brick_pop.sum()      # Build sparse membership list     rows = []     for h in range(n_hcps):         bricks_h = rng.choice(n_bricks, size=K[h], replace=False, p=brick_pop)         # visits per (h,b): more variable, depends on seniority & random         # visits = base + seniority effect + noise, then clipped >=0         base = rng.poisson(lam=2.5)  # baseline         for b in bricks_h:             visits = base + rng.poisson(lam=0.15 * seniority[h] + 1.0)             # exposure: use visits directly (or normalized variant)             w_hb = float(visits)             if w_hb == 0:                 w_hb = 0.5  # keep small exposure if assigned (optional)             rows.append((h, b, visits, w_hb))      hb = pd.DataFrame(rows, columns=["hcp_id", "brick_id", "visits", "w"])      # Make bricks heterogeneous: optionally drop/keep to target avg_hcps_per_brick     # We'll just report achieved distribution; simulation already creates variation.      # ----- (D) Generate latent z* and observed y -----     # z_{h,b} ~ Poisson(lambda_h * w_{h,b})     mu = lambda_true[hb["hcp_id"].to_numpy()] * hb["w"].to_numpy()     z_true = rng.poisson(lam=mu)      hb["z_true"] = z_true      # Aggregate observed sales by brick     y_by_brick = hb.groupby("brick_id")["z_true"].sum().rename("y").reset_index()      # Pack HCP table     hcp = pd.DataFrame({         "hcp_id": np.arange(n_hcps),         "specialty": spec,         "seniority": seniority,         "potential": potential,         "lambda_true": lambda_true,     })     for j, nm in enumerate(feature_names):         hcp[nm] = X[:, j]      meta = {         "feature_names": feature_names,         "beta_true": beta_true,         "n_hcps": n_hcps,         "n_bricks": n_bricks,     }      return hcp, hb, y_by_brick, meta   # Example usage hcp_df, hb_df, y_df, meta = simulate_hcp_brick_poisson(seed=42) print(hcp_df.head()) print(hb_df.head()) print(y_df.head()) print("beta_true:", meta["beta_true"]) 
```

### QuÃ© te devuelve

-   `hcp_df`: tabla HCP con features y `lambda_true`

-   `hb_df`: tabla de relaciones HCPâ€“brick con `w`, `visits`, y **ground truth** `z_true`

-   `y_df`: ventas observadas por brick (lo Ãºnico que normalmente tendrÃ­as)

-   `meta`: `beta_true` y nombres de features

## 3ï¸âƒ£ Variantes Ãºtiles (para stress testing)

Puedes hacer el mundo mÃ¡s â€œrealâ€ con:

-   **Overdispersion** (si Poisson se queda corto):

    -   usar Negative Binomial para (z\_{h,b})

-   **Zero inflation**:

    -   con probabilidad (p), (z\_{h,b}=0)

-   **Brick effects**:

    -   aÃ±adir un factor por brick (a_b): (\\mu\_{h,b} = \\lambda_h w\_{h,b} a_b)

-   **Dependencia en visitas**:

    -   que visitas dependan de especialidad o potencial

(Esto lo podemos aÃ±adir despuÃ©s si quieres testear robustez.)

## 4ï¸âƒ£ Â¿CÃ³mo evaluar si EM â€œrecupera la verdadâ€?

Cuando entrenes EM con **solo** (y_b), (w\_{h,b}) y (X_h), podrÃ¡s comparar:

### A) RecuperaciÃ³n de parÃ¡metros (si usas features)

-   Error en (\\beta):

    -   RMSE: (\|\\hat\\beta - \\beta\^\*\|)

    -   o correlaciÃ³n entre (X\\hat\\beta) y (X\\beta\^\*)

**RecomendaciÃ³n prÃ¡ctica:** comparar la productividad en escala log:

-   comparar ( \\eta_h = X_h\\beta ) (log-rate), suele ser mÃ¡s estable.

### B) RecuperaciÃ³n de atribuciÃ³n

Comparas matrices (en formato long) entre:

-   (z\^\**{h,b}) vs (\\hat z*{h,b} = \\mathbb{E}\[z\_{h,b}\\mid y,\\hat\\beta\])

MÃ©tricas tÃ­picas:

-   CorrelaciÃ³n por (h,b)

-   RMSE por (h,b)

-   Error relativo por brick (aunque por construcciÃ³n deberÃ­a sumar bien)

### C) Chequeos de calibraciÃ³n (must-have)

-   Por brick: (\\sum_h \\hat z\_{h,b} = y_b) (debe cumplirse numÃ©ricamente)

-   DistribuciÃ³n de residuales (si introduces overdispersion)

### D) MÃ©tricas de likelihood

-   Log-likelihood observada:\
    \[\
    \\sum_b \\log \\text{Poisson}\\Big(y_b \\mid \\sum_h \\hat\\lambda_h w\_{h,b}\\Big)\
    \]

-   Monitorizar que EM la **no disminuye** por iteraciÃ³n (sanity check)

## 5ï¸âƒ£ Nota: versiÃ³n â€œeurosâ€ (Gamma) en mock data

Si quieres simular euros:

-   genera (z\_{h,b}) Gamma con media proporcional a (\\theta_h w\_{h,b})

-   suma por brick para obtener (y_b)

La evaluaciÃ³n es igual, pero:

-   compara en escala log o con mÃ©tricas robustas (outliers pesan mÃ¡s).

------------------------------------------------------------------------

explica cada columna de hcp_df

------------------------------------------------------------------------

Perfecto â€” vamos **columna por columna**, con **significado estadÃ­stico** y **rol en el modelo**.\
Me centrarÃ© en `hcp_df`, que representa el **nivel HCP** (unidad individual).

# ğŸ“Š `hcp_df` â€” explicaciÃ³n detallada de cada columna

`hcp_df` contiene **una fila por HCP**.\
Conceptualmente mezcla **datos observables** + **verdad simulada** (solo para evaluaciÃ³n).

## ğŸ†” IdentificaciÃ³n

### **`hcp_id`**

-   Identificador Ãºnico del HCP

-   Tipo: entero

-   Uso:

    -   Clave para unir con `hb_df`

    -   Nunca entra directamente al modelo

## ğŸ§  Variables â€œrealesâ€ (observables en la vida real)

Estas son las **features que sÃ­ existirÃ­an en producciÃ³n**.

### **`specialty`**

-   Tipo: categÃ³rica (`GP`, `CARDIO`, `ENDO`, `ONCO`, `PULMO`)

-   Significado:

    -   Especialidad mÃ©dica del HCP

-   Uso:

    -   Se transforma a *one-hot* (ver columnas `spec_*`)

    -   Captura diferencias estructurales de productividad

ğŸ“Œ En el modelo:

> Diferentes especialidades â†’ diferente productividad esperada

### **`seniority`**

-   Tipo: entero (0â€“20)

-   Significado:

    -   AÃ±os de experiencia del HCP

-   Uso:

    -   Feature numÃ©rica

    -   Se escala (`seniority / 10`) para estabilidad numÃ©rica

ğŸ“Œ InterpretaciÃ³n:

> Cada +10 aÃ±os de seniority multiplica la tasa por `exp(Î²_seniority)`

### **`potential`**

-   Tipo: continuo positivo (lognormal)

-   Significado:

    -   Proxy de â€œpotencial comercialâ€ del HCP

-   Uso:

    -   Se transforma como `log1p(potential)`

    -   Reduce skew y hace la relaciÃ³n mÃ¡s lineal en log-space

ğŸ“Œ InterpretaciÃ³n:

> HCPs con mayor potencial generan mÃ¡s ventas esperadas

## ğŸ§® Variables de diseÃ±o (matriz (X_h))

Estas columnas **sÃ­ entran directamente** en:

\[\
\\lambda_h = \\exp(X_h \\beta)\
\]

### **`intercept`**

-   Siempre vale 1

-   Significado:

    -   Nivel base de productividad

-   Uso:

    -   Captura la tasa media cuando todas las demÃ¡s features son 0

ğŸ“Œ Sin intercept:

-   el modelo estarÃ­a forzado a pasar por el origen

-   mala idea en Poisson / Gamma

### **`seniority_x0.1`**

-   DefiniciÃ³n: `seniority / 10`

-   Tipo: continuo

-   Significado:

    -   VersiÃ³n escalada de seniority

-   Uso:

    -   Mejora convergencia del GLM

    -   Hace Î² mÃ¡s interpretable

ğŸ“Œ InterpretaciÃ³n de Î²:

> +0.2 â‡’ +10 aÃ±os â†’ \~+22% en tasa (exp(0.2))

### **`log1p_potential`**

-   DefiniciÃ³n: `log(1 + potential)`

-   Tipo: continuo

-   Significado:

    -   TransformaciÃ³n suave del potencial

-   Uso:

    -   Evita que outliers dominen el ajuste

ğŸ“Œ InterpretaciÃ³n:

> RelaciÃ³n multiplicativa y estable con la productividad

### **`spec_GP`, `spec_CARDIO`, `spec_ENDO`, `spec_ONCO`, `spec_PULMO`**

-   Tipo: binarias (0/1)

-   Significado:

    -   One-hot encoding de la especialidad

-   Uso:

    -   Permite efectos especÃ­ficos por especialidad

âš ï¸ Nota tÃ©cnica importante:

-   Con **intercept + todas las dummies** hay colinealidad perfecta

-   En producciÃ³n harÃ­as una de estas:

    -   eliminar una dummy (categorÃ­a de referencia)

    -   o usar regularizaciÃ³n (ridge)

-   En la simulaciÃ³n se tolera porque:

    -   queremos control total del ground truth

    -   EM + ridge lo maneja bien

ğŸ“Œ InterpretaciÃ³n:

> Î² positivo â‡’ esa especialidad es mÃ¡s productiva que la media

## ğŸ”® Variables de â€œground truthâ€ (NO observables en la vida real)

Estas columnas **solo existen para evaluaciÃ³n** del mÃ©todo.

### **`lambda_true`**

-   Tipo: continuo positivo

-   DefiniciÃ³n:\
    \[\
    \\lambda_h\^{\*} = \\exp(X_h \\beta\^{\*})\
    \]

-   Significado:

    -   Productividad real subyacente del HCP

-   Uso:

    -   Comparar con (\\hat\\lambda_h) estimado por EM

    -   DiagnÃ³stico de sesgo / varianza

ğŸ“Œ Nunca estarÃ­a disponible en datos reales.

## ğŸ§© Resumen por niveles

### ğŸ”¹ Observables reales

| Columna     | Uso                |
|-------------|--------------------|
| `hcp_id`    | IdentificaciÃ³n     |
| `specialty` | Feature categÃ³rica |
| `seniority` | Feature numÃ©rica   |
| `potential` | Feature numÃ©rica   |

### ğŸ”¹ DiseÃ±o del modelo

| Columna           | Entra en (X_h)? |
|-------------------|-----------------|
| `intercept`       | âœ”ï¸              |
| `seniority_x0.1`  | âœ”ï¸              |
| `log1p_potential` | âœ”ï¸              |
| `spec_*`          | âœ”ï¸              |

### ğŸ”¹ Solo para evaluaciÃ³n

| Columna       | En producciÃ³n |
|---------------|---------------|
| `lambda_true` | âŒ            |

## ğŸ§  Lectura mental correcta

> `hcp_df` define **quiÃ©n es el HCP** y **quÃ© esperamos de Ã©l en promedio**.\
> El EM **no aprende ventas por HCP directamente**,\
> aprende **cÃ³mo esas features explican ventas agregadas por brick**.

## âœ… Checkpoint

Â¿Quieres que hagamos lo mismo ahora con:

-   `hb_df` (HCPâ€“brick, exposiciones y `z_true`)

-   o `y_df` (ventas observadas por brick)

-   o pasamos ya a **CapÃ­tulo 7 â€” ImplementaciÃ³n completa del EM en Python**?

------------------------------------------------------------------------

si, haz lo mismo con las otras

------------------------------------------------------------------------

Perfecto. Vamos **igual de sistemÃ¡tico** con las otras dos tablas.\
Primero `hb_df` (nivel HCPâ€“Brick), luego `y_df` (nivel Brick).

# ğŸ“Š `hb_df` â€” tabla HCPâ€“Brick (el corazÃ³n del problema)

`hb_df` estÃ¡ en formato **long** y representa **una relaciÃ³n HCPâ€“Brick**.\
AquÃ­ viven **las variables latentes y la exposiciÃ³n**.

## ğŸ†” IdentificaciÃ³n y joins

### **`hcp_id`**

-   Identificador del HCP

-   FK hacia `hcp_df.hcp_id`

-   Uso:

    -   unir features (X_h)

    -   agrupar resultados por HCP

### **`brick_id`**

-   Identificador del brick

-   FK hacia `y_df.brick_id`

-   Uso:

    -   agrupar ventas observadas

    -   definir los conjuntos (\\mathcal{H}\_b)

## ğŸ“ˆ Variables de exposiciÃ³n (observables reales)

Estas columnas **sÃ­ existirÃ­an en producciÃ³n**.

### **`visits`**

-   Tipo: entero â‰¥ 0

-   Significado:

    -   NÃºmero de visitas del HCP al brick

-   Uso:

    -   Proxy de oportunidad / esfuerzo

    -   Puede entrar:

        -   directamente como `w_{h,b}`

        -   o como feature adicional en (X_h) o a nivel interacciÃ³n

ğŸ“Œ IntuiciÃ³n:

> A mÃ¡s visitas â†’ mayor exposiciÃ³n â†’ mÃ¡s ventas esperadas

### **`w`**

-   Tipo: continuo positivo

-   Significado:

    -   ExposiciÃ³n efectiva del HCP (h) en el brick (b)

-   Uso en el modelo:\
    \[\
    z\_{h,b} \\sim \\text{Poisson}(\\lambda_h , w\_{h,b})\
    \]

En la simulaciÃ³n:

-   `w â‰ˆ visits`

-   Con un pequeÃ±o floor para evitar ceros

ğŸ“Œ En producciÃ³n:

-   `w` puede ser:

    -   visitas

    -   share de territorio

    -   tiempo dedicado

    -   combinaciÃ³n ponderada

## ğŸ‘» Variables latentes (ground truth solo para evaluaciÃ³n)

### **`z_true`**

-   Tipo: entero â‰¥ 0

-   Significado:

    -   Ventas *reales* atribuibles al HCP (h) en el brick (b)

-   GeneraciÃ³n:\
    \[\
    z\_{h,b}\^\* \\sim \\text{Poisson}(\\lambda_h\^\* w\_{h,b})\
    \]

ğŸ“Œ En datos reales:

-   âŒ nunca observable

-   âœ”ï¸ es lo que EM intenta recuperar **en esperanza**

## ğŸ§  Rol conceptual de `hb_df`

Esta tabla:

-   Define **quiÃ©n compite con quiÃ©n** dentro de cada brick

-   Define las **restricciones estructurales**:\
    \[\
    y_b = \\sum\_{h\\in\\mathcal{H}*b} z*{h,b}\
    \]

-   Es donde vive el **E-step**

## ğŸ§© Resumen `hb_df`

| Columna    | Nivel     | En producciÃ³n | Rol                     |
|------------|-----------|---------------|-------------------------|
| `hcp_id`   | ID        | âœ”ï¸            | Join                    |
| `brick_id` | ID        | âœ”ï¸            | Join                    |
| `visits`   | Observada | âœ”ï¸            | Proxy esfuerzo          |
| `w`        | Observada | âœ”ï¸            | ExposiciÃ³n en el modelo |
| `z_true`   | Latente   | âŒ            | Ground truth            |

# ğŸ“Š `y_df` â€” tabla de ventas por Brick

`y_df` representa **exactamente lo que tienes en la vida real**.

## ğŸ†” IdentificaciÃ³n

### **`brick_id`**

-   Identificador Ãºnico del brick

-   Uso:

    -   define la unidad de observaciÃ³n

    -   join con `hb_df`

## ğŸ’° Variable objetivo observada

### **`y`**

-   Tipo: entero â‰¥ 0

-   Significado:

    -   Ventas totales del brick

-   DefiniciÃ³n:\
    \[\
    y_b = \\sum\_{h\\in\\mathcal{H}*b} z*{h,b}\
    \]

ğŸ“Œ Este es el **Ãºnico target real** del problema.

## ğŸ§  Rol conceptual de `y_df`

-   Es la **likelihood observada**

-   EM intenta explicar estos (y_b) usando:

    -   estructura de bricks (`hb_df`)

    -   productividad HCP (`hcp_df`)

-   No hay labels por HCP â†’ **problema inverso**

## ğŸ§© Resumen `y_df`

| Columna    | En producciÃ³n | Rol              |
|------------|---------------|------------------|
| `brick_id` | âœ”ï¸            | Identificador    |
| `y`        | âœ”ï¸            | Ventas agregadas |

## ğŸ”— CÃ³mo encajan las 3 tablas (lectura final)

```         
hcp_df   â†’  define Î»_h = exp(X_h Î²)    â†“ hb_df    â†’  define dÃ³nde y cuÃ¡nto se expone cada HCP (w_{h,b})    â†“ y_df     â†’  observa solo la suma por brick 
```

EM hace:

-   **E-step**: trabaja en `hb_df` (estima zÌ‚)

-   **M-step**: trabaja en `hcp_df` (actualiza Î²)

-   **Likelihood**: vive en `y_df`

## âœ… Checkpoint final

Con esto ya tienes:

-   modelo teÃ³rico âœ”ï¸

-   datos mock âœ”ï¸

-   interpretaciÃ³n de cada columna âœ”ï¸

Si quieres, el siguiente paso natural es:

ğŸ‘‰ **CapÃ­tulo 7 â€” ImplementaciÃ³n completa del EM en Python**,\
donde entrenamos el modelo con estos datos y medimos si recupera `beta_true` y `z_true`.