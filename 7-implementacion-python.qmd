# Implementación completa en Python

## Introducción

Este capítulo presenta una implementación completa del algoritmo **EM** en Python, construida desde cero (sin `sklearn`). La implementación incluye un *E-step* **vectorizado**, un *M-step* mediante **IRLS** (GLM Poisson con *offset*) con **ridge**, y un bloque de **debugging** orientado a los problemas típicos de producción.

[Download the notebook](em_hcp_brick_end_to_end.ipynb)

## Qué incluye el notebook (end-to-end)

-   **Generación de datos mock** (`hcp_df`, `hb_df`, `y_df`) con `beta_true`, `lambda_true`, `z_true`
-   **EM completo**:

    -   **E-step** vectorizado con `np.bincount`

    -   **M-step**: GLM Poisson con enlace log y **offset** `log(w_tilde)`, implementado con **IRLS** + **ridge**

-   **Convergencia**: trazado de log-likelihood observada por iteración y criterio de parada por cambio relativo en `beta`

-   **Evaluación** contra *ground truth*:

    -   correlación y RMSE en `η = Xβ` (más estable que comparar `β` directo si hay colinealidad)

    -   correlación y RMSE en `z_true` vs `zhat`

    -   check duro: por brick, `sum_h zhat_{h,b} == y_b`

## Puntos clave de implementación (por si quieres leerlo rápido)

### E-step vectorizado (la parte crítica)

En cada relación (fila) HCP–brick:

-   `num[r] = lambda_h[h[r]] * w[r]`

-   `den[b] = sum_{r: b[r]=b} num[r]`

-   `zhat[r] = y[b[r]] * num[r] / den[b[r]]`

Esto garantiza automáticamente:

$$
\sum_{h\in \mathcal{H}_b} \hat z_{h,b} = y_b.
$$

### M-step como GLM con offset

En el *M-step* se construyen agregados a nivel HCP:

-   `y_tilde[h] = sum_b zhat[h,b]`

-   `w_tilde[h] = sum_b w[h,b]`

-   Ajustas:

    $$
    \widetilde y_h \sim \operatorname{Poisson}(\exp(X_h\beta + \log \widetilde w_h)).
    $$

    con IRLS y ridge.

## Debugging típico (lo más útil en producción)

-   **Check #1**: `max |sum_h zhat - y|` por brick debe ser \~`1e-9`

-   **Check #2**: no debe haber bricks con `den[b]=0` (normalmente bricks sin HCPs o `w=0`)

-   **Check #3**: si tienes intercept + todas las dummies, usa **ridge** (el notebook lo hace)

-   **Check #4**: si `exp(Xβ)` explota, sube ridge o estandariza/clipea `η`

**Checkpoint**: al abrirlo y ejecutarlo, se debería observar:

-   log-likelihood creciendo y estabilizando

-   suma por brick consistente

-   correlaciones razonables `z_true` vs `zhat` y `η_true` vs `η_hat`

El siguiente paso continúa en el **Capítulo 8 — Unidades vs Euros (Poisson vs Gamma/Lognormal)**.

## Resumen

- El notebook implementa EM end-to-end con datos simulados (`hcp_df`, `hb_df`, `y_df`) y acceso a *ground truth* (`beta_true`, `lambda_true`, `z_true`).
- El *E-step* se implementa de forma vectorizada y garantiza la conservación de masa por brick: $\sum_{h\in \mathcal{H}_b}\hat z_{h,b}=y_b$.
- El *M-step* se resuelve como GLM Poisson con enlace log y *offset* `log(w_tilde)`, estimado con IRLS y regularización ridge.
- La validación incluye convergencia de la log-likelihood, chequeos estructurales (por brick) y métricas de recuperación sobre `η = Xβ` y sobre `z_true`.