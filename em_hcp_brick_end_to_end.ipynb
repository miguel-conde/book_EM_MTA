{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EM HCP-Brick (Poisson) — End-to-End\n",
        "\n",
        "Notebook generado automáticamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Generación de datos mock"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import math\n",
        "\n",
        "def simulate_hcp_brick_poisson(\n",
        "    n_hcps=400,\n",
        "    n_bricks=80,\n",
        "    avg_bricks_per_hcp=2.5,\n",
        "    seed=42,\n",
        "):\n",
        "    rng = np.random.default_rng(seed)\n",
        "\n",
        "    specialties = np.array([\"GP\", \"CARDIO\", \"ENDO\", \"ONCO\", \"PULMO\"])\n",
        "    spec = rng.choice(specialties, size=n_hcps, p=[0.45, 0.18, 0.15, 0.12, 0.10])\n",
        "\n",
        "    seniority = rng.integers(0, 21, size=n_hcps)  # 0..20\n",
        "    potential = rng.lognormal(mean=0.0, sigma=0.6, size=n_hcps)\n",
        "\n",
        "    spec_df = pd.get_dummies(spec, prefix=\"spec\")\n",
        "\n",
        "    X = np.column_stack([\n",
        "        np.ones(n_hcps),                # intercept\n",
        "        seniority / 10.0,               # scaled\n",
        "        np.log1p(potential),            # log feature\n",
        "        spec_df.to_numpy(),             # dummies (note: collinearity with intercept -> use ridge)\n",
        "    ])\n",
        "    feature_names = ([\"intercept\", \"seniority_x0.1\", \"log1p_potential\"]\n",
        "                     + list(spec_df.columns))\n",
        "\n",
        "    p = X.shape[1]\n",
        "\n",
        "    beta_true = np.zeros(p)\n",
        "    beta_true[0] = -0.3\n",
        "    beta_true[1] =  0.20\n",
        "    beta_true[2] =  0.55\n",
        "    for j, nm in enumerate(feature_names):\n",
        "        if nm == \"spec_CARDIO\":\n",
        "            beta_true[j] = 0.25\n",
        "        elif nm == \"spec_ONCO\":\n",
        "            beta_true[j] = 0.35\n",
        "        elif nm == \"spec_PULMO\":\n",
        "            beta_true[j] = 0.10\n",
        "        elif nm == \"spec_ENDO\":\n",
        "            beta_true[j] = 0.15\n",
        "\n",
        "    lambda_true = np.exp(X @ beta_true)\n",
        "\n",
        "    # Membership\n",
        "    K = rng.poisson(lam=avg_bricks_per_hcp, size=n_hcps)\n",
        "    K = np.clip(K, 1, max(1, n_bricks // 2))\n",
        "\n",
        "    brick_pop = rng.lognormal(mean=0.0, sigma=0.7, size=n_bricks)\n",
        "    brick_pop = brick_pop / brick_pop.sum()\n",
        "\n",
        "    rows = []\n",
        "    for h in range(n_hcps):\n",
        "        bricks_h = rng.choice(n_bricks, size=K[h], replace=False, p=brick_pop)\n",
        "        base = rng.poisson(lam=2.5)\n",
        "        for b in bricks_h:\n",
        "            visits = base + rng.poisson(lam=0.15 * seniority[h] + 1.0)\n",
        "            w = float(visits) if visits > 0 else 0.5\n",
        "            rows.append((h, b, visits, w))\n",
        "\n",
        "    hb = pd.DataFrame(rows, columns=[\"hcp_id\", \"brick_id\", \"visits\", \"w\"])\n",
        "\n",
        "    mu = lambda_true[hb[\"hcp_id\"].to_numpy()] * hb[\"w\"].to_numpy()\n",
        "    hb[\"z_true\"] = rng.poisson(lam=mu)\n",
        "\n",
        "    y_by_brick = hb.groupby(\"brick_id\")[\"z_true\"].sum().rename(\"y\").reset_index()\n",
        "\n",
        "    hcp = pd.DataFrame({\n",
        "        \"hcp_id\": np.arange(n_hcps),\n",
        "        \"specialty\": spec,\n",
        "        \"seniority\": seniority,\n",
        "        \"potential\": potential,\n",
        "        \"lambda_true\": lambda_true,\n",
        "    })\n",
        "    for j, nm in enumerate(feature_names):\n",
        "        hcp[nm] = X[:, j]\n",
        "\n",
        "    meta = {\"feature_names\": feature_names, \"beta_true\": beta_true}\n",
        "    return hcp, hb, y_by_brick, meta\n",
        "\n",
        "hcp_df, hb_df, y_df, meta = simulate_hcp_brick_poisson(seed=42)\n",
        "hcp_df.head(), hb_df.head(), y_df.head(), meta[\"feature_names\"], meta[\"beta_true\"][:6]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) EM desde cero (vectorizado + IRLS en M-step)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "def prepare_arrays(hcp_df, hb_df, y_df, feature_names):\n",
        "    brick_ids = np.sort(y_df[\"brick_id\"].unique())\n",
        "    brick_map = {bid: i for i, bid in enumerate(brick_ids)}\n",
        "    B = len(brick_ids)\n",
        "\n",
        "    h = hb_df[\"hcp_id\"].to_numpy().astype(int)\n",
        "    b = hb_df[\"brick_id\"].map(brick_map).to_numpy().astype(int)\n",
        "    w = hb_df[\"w\"].to_numpy().astype(float)\n",
        "\n",
        "    y = np.zeros(B, dtype=float)\n",
        "    idx = y_df[\"brick_id\"].map(brick_map).to_numpy().astype(int)\n",
        "    y[idx] = y_df[\"y\"].to_numpy().astype(float)\n",
        "\n",
        "    X = hcp_df[feature_names].to_numpy().astype(float)\n",
        "    return X, h, b, w, y, brick_ids\n",
        "\n",
        "def poisson_loglik_brick(y, mu):\n",
        "    lgamma = np.vectorize(math.lgamma)\n",
        "    return float(np.sum(y * np.log(mu + 1e-12) - mu - lgamma(y + 1.0)))\n",
        "\n",
        "def irls_poisson_ridge(X, y, offset=None, alpha=1e-3, max_iter=50, tol=1e-8):\n",
        "    n, p = X.shape\n",
        "    if offset is None:\n",
        "        offset = np.zeros(n, dtype=float)\n",
        "    beta = np.zeros(p, dtype=float)\n",
        "\n",
        "    for _ in range(max_iter):\n",
        "        eta = X @ beta + offset\n",
        "        mu = np.exp(eta)\n",
        "\n",
        "        W = mu\n",
        "        z = eta + (y - mu) / (mu + 1e-12)\n",
        "\n",
        "        sqrtW = np.sqrt(W)\n",
        "        Xw = X * sqrtW[:, None]\n",
        "        yw = (z - offset) * sqrtW\n",
        "\n",
        "        A = Xw.T @ Xw + alpha * np.eye(p)\n",
        "        rhs = Xw.T @ yw\n",
        "\n",
        "        beta_new = np.linalg.solve(A, rhs)\n",
        "        if np.linalg.norm(beta_new - beta) / (np.linalg.norm(beta) + 1e-12) < tol:\n",
        "            beta = beta_new\n",
        "            break\n",
        "        beta = beta_new\n",
        "\n",
        "    return beta\n",
        "\n",
        "def em_poisson_hcp_brick(\n",
        "    X, h, b, w, y,\n",
        "    alpha=1e-2,\n",
        "    max_em_iter=200,\n",
        "    tol=1e-6,\n",
        "    mstep_max_iter=50,\n",
        "    verbose=True,\n",
        "):\n",
        "    n_hcps, p = X.shape\n",
        "    B = int(np.max(b)) + 1\n",
        "\n",
        "    w_tilde = np.bincount(h, weights=w, minlength=n_hcps).astype(float)\n",
        "    offset = np.log(w_tilde + 1e-12)\n",
        "\n",
        "    beta = np.zeros(p, dtype=float)\n",
        "    history = {\"loglik\": [], \"rel_beta_change\": []}\n",
        "\n",
        "    for t in range(max_em_iter):\n",
        "        # E-step\n",
        "        lambda_h = np.exp(X @ beta)\n",
        "        num = lambda_h[h] * w\n",
        "        den = np.bincount(b, weights=num, minlength=B).astype(float)\n",
        "\n",
        "        zhat = y[b] * (num / (den[b] + 1e-12))\n",
        "\n",
        "        # M-step\n",
        "        y_tilde = np.bincount(h, weights=zhat, minlength=n_hcps).astype(float)\n",
        "        beta_new = irls_poisson_ridge(X, y_tilde, offset=offset, alpha=alpha, max_iter=mstep_max_iter)\n",
        "\n",
        "        ll = poisson_loglik_brick(y, den)\n",
        "        rel = float(np.linalg.norm(beta_new - beta) / (np.linalg.norm(beta) + 1e-12))\n",
        "        history[\"loglik\"].append(ll)\n",
        "        history[\"rel_beta_change\"].append(rel)\n",
        "\n",
        "        if verbose and (t % 10 == 0 or t < 5):\n",
        "            print(f\"EM iter {t:3d} | loglik={ll: .3f} | rel_beta_change={rel: .3e}\")\n",
        "\n",
        "        if rel < tol:\n",
        "            beta = beta_new\n",
        "            break\n",
        "        beta = beta_new\n",
        "\n",
        "    # final E-step\n",
        "    lambda_h = np.exp(X @ beta)\n",
        "    num = lambda_h[h] * w\n",
        "    den = np.bincount(b, weights=num, minlength=B).astype(float)\n",
        "    zhat = y[b] * (num / (den[b] + 1e-12))\n",
        "    return beta, history, zhat\n",
        "\n",
        "X, h, b, w, y, brick_ids = prepare_arrays(hcp_df, hb_df, y_df, meta[\"feature_names\"])\n",
        "beta_hat, hist, zhat = em_poisson_hcp_brick(X, h, b, w, y, alpha=1e-2, verbose=True)\n",
        "beta_hat[:8], meta[\"beta_true\"][:8], len(hist[\"loglik\"]), hist[\"loglik\"][-1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) Evaluación contra ground truth"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "beta_true = meta[\"beta_true\"]\n",
        "\n",
        "param_df = pd.DataFrame({\n",
        "    \"feature\": meta[\"feature_names\"],\n",
        "    \"beta_true\": beta_true,\n",
        "    \"beta_hat\": beta_hat,\n",
        "    \"diff\": beta_hat - beta_true,\n",
        "})\n",
        "display(param_df.head(12))\n",
        "\n",
        "eta_true = X @ beta_true\n",
        "eta_hat = X @ beta_hat\n",
        "corr_eta = np.corrcoef(eta_true, eta_hat)[0, 1]\n",
        "rmse_eta = float(np.sqrt(np.mean((eta_true - eta_hat) ** 2)))\n",
        "print(\"corr(eta_true, eta_hat) =\", corr_eta)\n",
        "print(\"rmse(eta_true, eta_hat) =\", rmse_eta)\n",
        "\n",
        "hb_eval = hb_df.copy()\n",
        "hb_eval[\"zhat\"] = zhat\n",
        "corr_z = np.corrcoef(hb_eval[\"z_true\"], hb_eval[\"zhat\"])[0, 1]\n",
        "rmse_z = float(np.sqrt(np.mean((hb_eval[\"z_true\"] - hb_eval[\"zhat\"]) ** 2)))\n",
        "print(\"corr(z_true, zhat) =\", corr_z)\n",
        "print(\"rmse(z_true, zhat) =\", rmse_z)\n",
        "\n",
        "brick_sum = hb_eval.groupby(\"brick_id\")[[\"z_true\", \"zhat\"]].sum().reset_index()\n",
        "brick_sum = brick_sum.merge(y_df, on=\"brick_id\", how=\"left\")\n",
        "brick_sum[\"zhat_minus_y\"] = brick_sum[\"zhat\"] - brick_sum[\"y\"]\n",
        "print(\"max |sum_h zhat - y| =\", float(brick_sum[\"zhat_minus_y\"].abs().max()))\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(hist[\"loglik\"])\n",
        "plt.xlabel(\"EM iteration\")\n",
        "plt.ylabel(\"Observed log-likelihood\")\n",
        "plt.title(\"EM convergence (log-likelihood)\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Debugging típico de EM (checklist)\n",
        "\n",
        "1) **Suma por brick**: `sum_h zhat_{h,b}` debe ser exactamente `y_b` (errores ~1e-9).  \n",
        "2) **Denominadores**: `den[b]` no debe ser 0; si lo es, bricks sin HCPs o `w=0`.  \n",
        "3) **Colinealidad**: intercept + todas las dummies => usa ridge (`alpha>0`) o elimina una dummy.  \n",
        "4) **Offsets**: `w_tilde` debe ser >0 para todos los HCPs incluidos (si no, filtra).  \n",
        "5) **Overflow**: `exp(X beta)` puede desbordar => estandariza/clip `eta` o sube regularización.  \n",
        "6) **Monotonicidad**: loglik observada no debería bajar; si baja, suele ser bug en el M-step.  \n",
        "7) **Convergencia falsa**: si beta no cambia pero loglik es mala, revisa inicialización/alpha.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}