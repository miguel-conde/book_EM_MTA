# Modelo probabil√≠stico base (sin covariables)

## 1Ô∏è‚É£ Notaci√≥n formal (dejamos esto fijo para todo el curso)

### √çndices

-   $h = 1,\dots,H$ ‚Üí HCPs

-   $b = 1,\dots,B$ ‚Üí Bricks

### Conjuntos

-   $\mathcal{H}_b \subset \{1,\dots,H\}$: HCPs que pertenecen al brick $b$

### Variables observadas

-   $y_b \in \mathbb{R}^+$: ventas totales del brick $b$

-   $w_{h,b} \ge 0$: exposici√≥n del HCP $h$ en el brick $b$  
    (por ahora puede ser 1 si hay pertenencia)

### Par√°metros (a estimar)

-   $\theta_h$: productividad latente del HCP $h$

## 2Ô∏è‚É£ Variable latente clave

Definimos:

$$
z_{h,b} \equiv \text{ventas atribuibles al HCP } h \text{ en el brick } b
$$

con la **restricci√≥n estructural**:

$$
\sum_{h \in \mathcal{H}_b} z_{h,b} = y_b
$$

üìå Esta restricci√≥n es lo que hace el problema **no trivial**.

## 3Ô∏è‚É£ Caso A ‚Äî Ventas en **unidades** (Poisson)

### üîπ Supuesto generativo

Cada HCP genera ventas de forma independiente:

$$
z_{h,b} \sim \text{Poisson}(\lambda_h w_{h,b})
$$

donde:

-   $\lambda_h > 0$: tasa base del HCP

-   $w_{h,b}$: exposici√≥n en el brick

### üîπ Propiedad clave (aditividad)

La suma de Poisson independientes es Poisson:

$$
y_b = \sum_{h \in b} z_{h,b}
\quad \Rightarrow \quad
y_b \sim \text{Poisson}\left(\sum_{h \in b} \lambda_h w_{h,b}\right)
$$

üìå Esta propiedad **justifica EM** y simplifica enormemente el E-step.

### üîπ Likelihood marginal (observada)

$$
\mathcal{L}_{\text{obs}}(\lambda)=
\prod_{b=1}^B
	ext{Poisson}\left(y_b \,\Big|\, \sum_{h \in b} \lambda_h w_{h,b}\right)
$$

### üîπ Likelihood completa (con latentes)

$$
\mathcal{L}_{\text{comp}}(\lambda)=
\prod_{b=1}^B
\prod_{h \in b}
	ext{Poisson}\left(z_{h,b} \,\big|\, \lambda_h w_{h,b}\right)
$$

üìå EM optimiza la **esperanza del log** de esta expresi√≥n.

## 4Ô∏è‚É£ Caso B ‚Äî Ventas en **euros** (continuas)

Aqu√≠ ya no podemos usar Poisson. Dos opciones realistas:

### üîπ Opci√≥n 1: **Gamma** (mi favorita en este contexto)

#### Supuesto

$$
z_{h,b} \sim \text{Gamma}(k, \theta_h w_{h,b})
$$

-   Media: $\mathbb{E}[z_{h,b}] = k \theta_h w_{h,b}$

-   Varianza proporcional a la media

-   Soporta asimetr√≠a

üìå Muy usada en revenue modeling.

#### Suma

Si todos los ( k ) son iguales:

$$
y_b = \sum_{h \in b} z_{h,b}
\sim \text{Gamma}\left(k|\mathcal{H}_b|,\, \sum_{h \in b} \theta_h w_{h,b}\right)
$$

### üîπ Opci√≥n 2: **Lognormal** (m√°s fr√°gil)


$$
\log z_{h,b} \sim \mathcal{N}(\mu_h + \log w_{h,b}, \sigma^2)
$$

Problemas:

-   La suma no es lognormal

-   EM requiere aproximaciones

-   Sensible a outliers

üìå √ötil si hay colas muy pesadas, pero m√°s compleja.

## 5Ô∏è‚É£ Likelihood completa vs marginal (el coraz√≥n de EM)

### üîπ Likelihood completa

La que *queremos* maximizar:

$$
\log p(\{y_b, z_{h,b}\} \mid \theta)
= \sum_{b,h} \log p(z_{h,b} \mid \theta_h)
$$

pero **no podemos** porque $z_{h,b}$ no se observa.

### üîπ Likelihood marginal (observada)

$$
\log p(\{y_b\} \mid \theta)
= \sum_b \log
\int
\prod_{h \in b} p(z_{h,b} \mid \theta_h)
\,\delta\Big(\sum_{h \in b} z_{h,b} - y_b\Big)
\,dz
$$

üìå Integral intratable ‚Üí EM.

## 6Ô∏è‚É£ Qu√© har√° EM exactamente (preview)

-   **E-step**\
    Calcula:\
    $$
    \mathbb{E}[z_{h,b} \mid y_b, \theta^{(t)}]
    $$

-   **M-step**\
    Actualiza:
    $$
    	heta_h^{(t+1)} =
    \arg\max_{\theta_h}
    \sum_b \mathbb{E}[z_{h,b}]\, \log p(z_{h,b} \mid \theta_h)
    $$

## 7Ô∏è‚É£ ‚úîÔ∏è SALIDA ‚Äî Likelihood formal del problema

### üîπ Unidades (Poisson)

$$
\boxed{y_b \sim \text{Poisson}\left(\sum_{h \in b} \lambda_h w_{h,b}\right)}
$$

con latentes:\
$$
z_{h,b} \sim \text{Poisson}(\lambda_h w_{h,b})
$$

### üîπ Euros (Gamma)

$$
\boxed{y_b \sim \text{Gamma}\left(k|\mathcal{H}_b|,\, \sum_{h \in b} \theta_h w_{h,b}\right)}
$$

------------------------------------------------------------------------

Cuando has dicho "Si conoci√©ramos ùëß ‚Ñé , ùëè z h,b ‚Äã

:

Podr√≠amos estimar f√°cilmente productividad de HCPs" y "Si conoci√©ramos la productividad de HCPs:" -\> qu√© est√°s entendiendo como productividad?

------------------------------------------------------------------------

Excelente pregunta ‚Äî y muy importante aclararla ahora, porque **‚Äúproductividad‚Äù puede significar cosas muy distintas** seg√∫n el nivel del modelo. Vamos a dejarla **formal, precisa y sin ambig√ºedad**.

## üîë Qu√© significa ‚Äúproductividad‚Äù en ESTE curso

Cuando digo **productividad del HCP**, **NO** me refiero a:

-   performance comercial ‚Äúreal‚Äù

-   causal uplift

-   impacto incremental puro

-   eficiencia del visitador

üëâ Me refiero **estrictamente** a un **par√°metro del modelo generativo**.

## 1Ô∏è‚É£ Definici√≥n formal (modelo base sin covariables)

### üîπ Caso unidades (Poisson)

La **productividad del HCP ( h )** es:

$$
\boxed{\lambda_h = \mathbb{E}[\text{unidades generadas por } h \text{ por unidad de exposici√≥n}]}
$$

y el modelo dice:

$$
z_{h,b} \sim \text{Poisson}(\lambda_h w_{h,b})
$$

Interpretaci√≥n:

-   A igualdad de exposici√≥n $w_{h,b}$

-   Un HCP con mayor $\lambda_h$

-   ‚Äúgenera‚Äù m√°s unidades **en promedio**

üìå Es **una tasa**, no un efecto causal.

### üîπ Caso euros (Gamma)

Aqu√≠ la productividad es:

$$
\boxed{\theta_h = \mathbb{E}[\text{‚Ç¨ generados por } h \text{ por unidad de exposici√≥n}]}
$$

con:

$$
z_{h,b} \sim \text{Gamma}(k, \theta_h w_{h,b})
$$

üìå Es el **nivel medio de revenue** atribuible al HCP.

## 2Ô∏è‚É£ ‚ÄúSi conoci√©ramos $z_{h,b}$, podr√≠amos estimar productividad‚Äù

Ahora s√≠, con precisi√≥n:

### üîπ Sup√≥n que $z_{h,b}$ es observado

Entonces para Poisson:

$$
\hat{\lambda}_h = \frac{\sum_b z_{h,b}}{\sum_b w_{h,b}}
$$

Es el **MLE cerrado** del Poisson.

üëâ No hay EM, no hay dificultad, no hay ambig√ºedad.

## 3Ô∏è‚É£ ‚ÄúSi conoci√©ramos la productividad, podr√≠amos repartir ventas‚Äù

Sup√≥n ahora que conocemos ( \\lambda_h ).

Entonces, para un brick ( b ):

$$
\mathbb{E}[z_{h,b} \mid y_b]
= y_b\cdot
\frac{\lambda_h w_{h,b}}{\sum_{h' \in b} \lambda_{h'} w_{h',b}}
$$

üìå Esta es la **regla de atribuci√≥n** del E-step.

Interpretaci√≥n:

-   No decimos ‚Äúel HCP h vendi√≥ exactamente X‚Äù

-   Decimos ‚Äúdado su nivel esperado, le corresponde esta fracci√≥n‚Äù

## 4Ô∏è‚É£ Importante: lo que *NO* es productividad

Muy importante para evitar malinterpretaciones posteriores:

‚ùå No es:

-   efecto incremental causal

-   lift por visita

-   ROI del visitador

-   impacto neto frente a control

‚úîÔ∏è S√≠ es:

-   un **par√°metro latente**

-   coherente con los datos agregados

-   interpretable *dentro del modelo*

Si ma√±ana cambiamos el modelo (por ejemplo, jer√°rquico bayesiano), **la productividad cambia de significado**.

## 5Ô∏è‚É£ Cuando a√±adamos covariables (preview)

En el **Cap√≠tulo 5**, redefiniremos:

$$
\lambda_h = \exp(X_h \beta)
$$

Aqu√≠ la productividad:

-   ya no es un par√°metro libre

-   es una **funci√≥n de features**

-   permite generalizar a HCPs nuevos

Pero la interpretaci√≥n base **no cambia**:

> ‚Äúnivel esperado de generaci√≥n de ventas por exposici√≥n‚Äù

## ‚úÖ Checkpoint conceptual

Dime si esta definici√≥n te parece:

-   ‚úîÔ∏è clara

-   ‚úîÔ∏è defendible ante negocio

-   ‚úîÔ∏è compatible con tu intuici√≥n

Si est√°s OK, en el siguiente mensaje arrancamos **Cap√≠tulo 3 ‚Äî EM paso a paso (E-step y M-step expl√≠citos)**, ya con f√≥rmulas cerradas.

------------------------------------------------------------------------

no he entendido bien. Qu√© hace credit attribution y en que se diferencia de em?

------------------------------------------------------------------------

Muy bien que pares aqu√≠: esta confusi√≥n es **normal incluso en equipos senior**, porque *credit attribution* y *EM* se usan muchas veces como si fueran lo mismo‚Ä¶ y **no lo son**.\
Voy a explicarlo **conceptualmente**, sin matem√°ticas innecesarias.

# üîç Credit Attribution vs EM

### Qu√© hace cada uno y en qu√© se diferencian

## 1Ô∏è‚É£ ¬øQu√© es **Credit Attribution**?

### üëâ Es un **objetivo**, no un algoritmo

**Credit attribution** significa:

> *Asignar una fracci√≥n de un resultado agregado (venta, revenue, conversi√≥n) a varios agentes que han participado.*

Ejemplos:

-   Marketing: repartir una conversi√≥n entre canales

-   Tu caso: repartir ventas del brick entre HCPs

-   Finanzas: repartir P&L entre desks

üìå **No dice c√≥mo hacerlo**, solo **qu√© quieres obtener**.

### üîπ Resultado t√≠pico

Algo como:

| Brick | HCP | Cr√©dito asignado |
|-------|-----|------------------|
| B1    | H1  | 30%              |
| B1    | H2  | 50%              |
| B1    | H3  | 20%              |

Eso **es credit attribution**.

## 2Ô∏è‚É£ ¬øQu√© NO es credit attribution?

-   ‚ùå No es necesariamente estad√≠stico

-   ‚ùå No implica likelihood

-   ‚ùå No implica variables latentes

-   ‚ùå No implica inferencia

Ejemplos de *credit attribution* **no estad√≠stico**:

-   Repartir ventas proporcionalmente al n¬∫ de visitas

-   Repartir ventas a partes iguales

-   Reglas de negocio (‚Äúel m√°s senior se lleva m√°s‚Äù)

üëâ Todos hacen attribution, **ninguno usa EM**.

## 3Ô∏è‚É£ Entonces, ¬øqu√© es **EM**?

### üëâ EM es un **algoritmo de inferencia estad√≠stica**

EM responde a:

> *Dado un modelo probabil√≠stico con variables latentes, ¬øc√≥mo estimo sus par√°metros?*

EM:

-   Maximiza una **likelihood**

-   Asume un **modelo generativo**

-   Produce estimaciones consistentes (bajo supuestos)

üìå EM **no tiene como objetivo principal repartir cr√©ditos**,\
eso es una **consecuencia** del E-step.

## 4Ô∏è‚É£ Relaci√≥n exacta entre ambos (la clave)

### üîë En tu problema:

-   **Credit attribution** =\
    ‚Äú¬øCu√°nto de la venta del brick corresponde a cada HCP?‚Äù

-   **EM** =\
    ‚Äú¬øQu√© valores de productividad y contribuciones latentes explican mejor los datos agregados?‚Äù

### üîÅ Conexi√≥n

En EM:

-   El **E-step** calcula:\
    $$
    \mathbb{E}[z_{h,b} \mid y_b]
    $$

-   Eso **es una attribution probabil√≠stica**

üëâ Pero:

-   La attribution **no es el objetivo**

-   Es un **subproducto necesario** para aprender el modelo

## 5Ô∏è‚É£ Diferencia en una tabla clara

| Aspecto             | Credit Attribution | EM              |
|---------------------|--------------------|-----------------|
| Qu√© es              | Objetivo           | Algoritmo       |
| Define              | Qu√© se reparte     | C√≥mo se infiere |
| Requiere modelo     | No                 | S√≠              |
| Usa likelihood      | No                 | S√≠              |
| Produce par√°metros  | No                 | S√≠              |
| Produce attribution | S√≠                 | Indirectamente  |

## 6Ô∏è‚É£ Analog√≠a muy clara (mental model)

### üéÇ Repartir una tarta

-   **Credit attribution**:\
    ‚Äú¬øC√≥mo repartimos la tarta entre 5 personas?‚Äù

-   **EM**:\
    ‚ÄúAsumimos que cada persona tiene un apetito distinto (latente).\
    Observamos cu√°nto se comi√≥ el grupo en total.\
    Inferimos los apetitos y, como consecuencia, cu√°nto comi√≥ cada uno.‚Äù

üëâ EM **explica** el reparto, no lo decide arbitrariamente.

## 7Ô∏è‚É£ Resumen en una frase (para que te quede)

> **Credit attribution es el *qu√©***\
> **EM es el *c√≥mo*, bajo un modelo estad√≠stico expl√≠cito**

## ‚úÖ Checkpoint

Dime si ahora ves clara esta separaci√≥n:

-   ¬øTe queda claro que **EM no es un m√©todo de attribution**, sino un m√©todo de inferencia?

-   ¬øVes por qu√© *muchos* sistemas de attribution **no necesitan EM**, pero el tuyo s√≠?

Si est√°s OK, en el siguiente paso entramos de lleno en **Cap√≠tulo 3 ‚Äî EM paso a paso**, donde ver√°s c√≥mo la attribution sale *autom√°ticamente* del E-step.

------------------------------------------------------------------------

es decir, que EM es una de las posibles maneras de C√ìMO hacer credit attribution (el QU√â). Otras maneras son mixture models y bayesian inference. Es as√≠?

------------------------------------------------------------------------

Casi perfecto üëç ‚Äî solo hace falta **un peque√±o ajuste conceptual** para que quede *exactamente correcto*.\
Voy a dejarlo cristalino y cerramos esta parte.

## ‚úÖ La forma correcta de pensarlo

### ‚úîÔ∏è Lo que **s√≠** es correcto

-   **Credit attribution** es el **QU√â**\
    ‚Üí repartir un resultado agregado entre agentes

-   Existen **muchas maneras** de hacer credit attribution

### ‚ùó El ajuste importante

**Mixture models NO son una alternativa a EM**\
**Bayesian inference NO es una alternativa a EM**

üëâ Est√°n en **niveles distintos del stack conceptual**.

## üß± Stack correcto (de arriba a abajo)

### 1Ô∏è‚É£ **QU√â** ‚Äî Credit attribution

> El problema de negocio

Ejemplo:

-   Repartir ventas del brick entre HCPs

### 2Ô∏è‚É£ **MODELO** ‚Äî Mixture / Latent variable model

> C√≥mo supones que se generan los datos

Ejemplos:

-   Mixture model

-   Latent additive model

-   Hierarchical model

üìå Aqu√≠ decides **qu√© es $z_{h,b}$** y c√≥mo se genera.

### 3Ô∏è‚É£ **C√ìMO INFERIR** ‚Äî EM / Bayesian / VI

> C√≥mo estimas los par√°metros del modelo

Ejemplos:

-   **EM** ‚Üí Maximum Likelihood con latentes

-   **Bayesian inference** ‚Üí posterior completo

-   **Variational inference** ‚Üí aproximaci√≥n

## üìä D√≥nde encaja EM exactamente

EM es:

> **Una forma de inferir par√°metros en modelos con variables latentes**

No es:

-   ni el problema

-   ni el modelo

## üîÅ Reescribiendo tu frase (100% correcta)

Tu frase:

> *‚ÄúEM es una de las posibles maneras de C√ìMO hacer credit attribution (el QU√â). Otras maneras son mixture models y bayesian inference.‚Äù*

La versi√≥n **exacta** ser√≠a:

> **‚ÄúCredit attribution es el QU√â.\
> Definimos un modelo latente (por ejemplo, un mixture model).\
> EM es una de las maneras de inferir ese modelo; la inferencia bayesiana es otra.‚Äù**

## üß† Ejemplo concreto (tu caso)

-   QU√â:\
    Repartir ventas del brick entre HCPs

-   MODELO:\
    $z_{h,b} \sim \text{Poisson}(\lambda_h w_{h,b})$

-   C√ìMO (opci√≥n A):\
    EM ‚Üí MLE de $\lambda_h$

-   C√ìMO (opci√≥n B):\
    Bayes ‚Üí $p(\lambda_h \mid y)$

Ambos producen:

-   una attribution

-   pero con propiedades distintas

## üìå Regla mental √∫til (para siempre)

> **Model ‚â† Inference ‚â† Business objective**

Si confundes uno con otro:

-   los modelos se vuelven ‚Äúreligi√≥n‚Äù

-   las discusiones con negocio se rompen