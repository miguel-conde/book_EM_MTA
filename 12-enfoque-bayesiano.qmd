# Enfoque bayesiano jerárquico (BHM): cuándo y por qué

## Introducción

Este capítulo describe el planteamiento de un **enfoque bayesiano jerárquico** (*Bayesian Hierarchical Model*, BHM) como alternativa al uso de **EM** con estimación puntual (*maximum likelihood*, MLE) en el problema “agregado → desagregado”. La idea central consiste en inferir el **modelo generativo completo**, incluidas las **variables latentes**, mediante **inferencia bayesiana**, en lugar de obtener estimadores puntuales para los parámetros.

El cambio no se reduce a “poner priors”: el enfoque bayesiano modifica qué se estima, qué significa el resultado, cómo se controla el *overfitting* y qué preguntas operativas se pueden responder. A lo largo del capítulo se presenta (i) la formulación del modelo, (ii) la organización de los datos, (iii) el tratamiento de las variables latentes, (iv) las salidas del modelo y (v) el papel de los grupos y las jerarquías, incluyendo el caso en el que la jerarquía llega hasta creatividad.

---

## 1. EM vs bayesiano: qué cambia realmente

### EM (lo que ya se ha usado en el libro)

En EM se asume un modelo generativo, se trata $z$ como variable latente y se optimiza un criterio de tipo MLE:
$$
\hat\theta = \arg\max_\theta p(y \mid \theta).
$$

El resultado típico es doble: (i) estimaciones puntuales (por ejemplo, $\hat\lambda$ o $\hat\beta$) y (ii) una asignación esperada $\mathbb{E}[z \mid y, \hat\theta]$. En este planteamiento no hay **incertidumbre explícita** en forma de distribución posterior.

### Bayesiano jerárquico

En un enfoque bayesiano jerárquico se define el mismo modelo generativo, pero se trata **todo** como variable aleatoria (productividades, coeficientes y, en algunos diseños, los propios $z$). El objetivo es inferir la posterior completa:
$$
p(\theta, z \mid y).
$$

La salida deja de ser un punto y pasa a ser una **distribución posterior**: aparecen *shrinkage* automático, intervalos creíbles y decisiones basadas en riesgo.

---

## 2. Modelo generativo (forma general)

La formulación puede escribirse de manera canónica para ambos casos de uso del libro.

**Observado.** Un agregado (por ejemplo, ventas en un brick o contribución incremental de MMM):
$$
y_b \quad \text{o} \quad C_{m,t,g}.
$$

**Latente.** Contribuciones individuales no negativas cuya suma reproduce el agregado:
$$
z_{i,b} \ge 0,\quad \sum_i z_{i,b} = y_b.
$$

### Nivel 1 — Likelihood (conceptualmente idéntico a EM)

Ejemplo Poisson (unidades):
$$
z_{i,b} \sim \operatorname{Poisson}(\lambda_i\, w_{b,i}).
$$

Ejemplo Gamma (euros):
$$
z_{i,b} \sim \operatorname{Gamma}(k,\ \theta_i\, w_{b,i}).
$$

Y, estructuralmente:
$$
y_b = \sum_i z_{i,b}.
$$

Hasta aquí no hay diferencia conceptual con EM: el cambio aparece al especificar priors y jerarquías para regularizar y cuantificar incertidumbre. La notación $w$ representa la **exposición** (en otros textos se escribe $\omega$).

---

## 3. Dónde entra lo bayesiano: jerarquía y priors

### Nivel 2 — Productividades jerárquicas

En lugar de fijar determinísticamente una relación del tipo
$$
\lambda_i = \exp(X_i \beta),
$$
puede definirse una jerarquía probabilística, por ejemplo:
$$
\begin{aligned}
\beta &\sim \mathcal{N}(0, \sigma_\beta^2) \\
\lambda_i &\sim \operatorname{LogNormal}(X_i \beta,\ \sigma_\lambda^2).
\end{aligned}
$$

Otra opción equivalente desde la perspectiva de *pooling* consiste en modelar por grupos:
$$
\lambda_{i,g} \sim \operatorname{LogNormal}(\mu_g,\ \sigma_g).
$$

Esto introduce *pooling*, regularización automática y control del *cold start*.

### Nivel 3 — Hyperpriors

Para evitar soluciones inestables, los hiperparámetros también se regularizan:
$$
\mu_g \sim \mathcal{N}(0, 1)
\quad
\sigma_g \sim \operatorname{HalfNormal}(0.5).
$$

---

## 4. Tratamiento de las variables latentes $z$

En la práctica aparecen dos estrategias.

### Opción A — Integrar $z$ (la más común)

No se muestrea $z$ explícitamente. Se usa la propiedad de cierre (suma de Poisson es Poisson; suma de Gamma es Gamma). Por ejemplo:
$$
y_b \sim \operatorname{Poisson}\Big(\sum_i \lambda_i\, w_{b,i}\Big).
$$

Esto reduce el número de variables, mejora la escalabilidad y hace la inferencia más estable. El $z$ se recupera a posteriori como expectativa.

### Opción B — Muestrear $z$ explícitamente (más literal)

Se modela el vector completo de asignaciones:
$$
(z_{1,b}, \dots, z_{K,b}) \sim \operatorname{Multinomial}\big(y_b,\ p_{i,b}\big),
$$
con
$$
p_{i,b} \propto \lambda_i\, w_{b,i}.
$$

Esta formulación es interpretativa y produce asignaciones explícitas, pero escala peor por el número de variables latentes. En producción se usa casi siempre la opción A.

---

## 5. Organización de los datos

Un formato natural es el formato *long* (análogo al usado en EM):

| b (brick / m,t,g) | i (hcp / campaign) | $w$ | $X_i$ | $y_b$ |
| ----------------- | ------------------ | --- | ----- | ----- |

En Bayes no es necesario duplicar $y_b$ en cada fila: puede agruparse por $b$ y usar sumas en el término $\sum_i \lambda_i\, w_{b,i}$.

---

## 6. Inferencia: cómo se estima

El mayor cambio operativo frente a EM es el mecanismo de inferencia.

### MCMC (NUTS)

Se implementa típicamente en PyMC o Stan. Es preciso, pero lento y difícil de escalar; se usa en investigación, validación y datasets pequeños.

### Variational Inference (VI)

VI aproxima la posterior y es mucho más rápido, a costa de menor precisión. En la práctica industrial se utilizan con frecuencia PyMC VI, NumPyro SVI o Pyro SVI.

---

## 7. Salidas del modelo

### En EM

* $\hat\lambda_i$
* $\hat z_{i,b}$

### En bayesiano

* Posterior de $\lambda_i$ (media e intervalos creíbles)
* Posterior predictivo de $z_{i,b}$
* Incertidumbre por campaña, periodo y grupo
* Probabilidad de que campaña A sea mayor que campaña B
* Probabilidad de que $\text{uplift} > 0$

---

## 8. Cuándo merece la pena el enfoque bayesiano

El enfoque bayesiano jerárquico resulta especialmente útil cuando hay *cold start*, se necesitan intervalos de confianza, se modelan jerarquías profundas o el coste de una mala decisión es alto. En cambio, no suele compensar si la prioridad es escalar rápido, si solo se busca ranking, si el negocio no puede trabajar con incertidumbre o si el MMM ya es el cuello de botella.

---

## 9. Regla mental

> **EM estima “el mejor reparto”.
> Bayesiano estima “qué repartos son plausibles y con qué incertidumbre”.**

El cambio no es únicamente sustituir MLE por Bayes; cambia la pregunta que se hace al modelo.

---

## 10. Uso típico en la práctica

En organizaciones maduras suele verse un patrón mixto:

1. EM para *baseline*, escalabilidad y explicabilidad.
2. Bayesiano para *cold start*, validación y decisiones de alto riesgo.
3. Enfoques híbridos (EM con *shrinkage* inspirado en Bayes).

Como siguiente paso, suele ser razonable escribir el modelo completo en PyMC/NumPyro como pseudocódigo, comparar EM vs VI en el mismo dataset o diseñar un roadmap de madurez analítica (EM → Bayes).

---

## 11. Grupos y jerarquías: ejemplos operativos

En un BHM, un **grupo** es un conjunto de entidades para las cuales se asume que sus productividades no son iguales, pero tampoco completamente independientes (*partial pooling*). En forma compacta:
$$
\lambda_i \sim \operatorname{LogNormal}(\mu_{\text{grupo}(i)},\ \sigma_{\text{grupo}(i)}).
$$

### 11.1. Grupos en HCP–Brick

**Especialidad médica.** El grupo es la especialidad del HCP (GP, Cardio, Endo, Onco). La motivación es que médicos de la misma especialidad tienden a compartir patrones de prescripción y a responder de manera parecida a visitas; un GP nuevo se parece más a otros GPs que a un Onco. Un esquema típico es:
$$
\begin{aligned}
\lambda_h &\sim \operatorname{LogNormal}(\mu_{\text{spec}(h)},\ \sigma_{\text{spec}}) \\
\mu_{\text{spec}} &\sim \mathcal{N}(\mu_0,\ \sigma_0).
\end{aligned}
$$

**Seniority buckets.** El grupo es un bucket de seniority (0–2 años, 3–7 años, 8+ años). Se usa cuando se considera que médicos jóvenes tienen menos impacto y que los perfiles senior son más estables.

**Región.** El grupo es la región (Norte/Centro/Sur; Urbano/Rural). Es útil cuando el mercado no es homogéneo y existen diferencias estructurales.

### 11.2. Grupos en MMM → MTA (campañas / creatividades)

**Tipo de campaña (objective).** El grupo es el objetivo (Awareness, Consideration, Conversion). La intuición es que campañas de awareness saturan antes y suelen tener menor eficiencia directa, mientras que campañas de conversión tienden a tener menos volumen y más impacto por impresión. Un ejemplo de parametrización es:
$$
\lambda_{m,k} \sim \operatorname{LogNormal}(\mu_{\text{objective}(k)},\ \sigma_{\text{objective}}).
$$

**Formato creativo.** El grupo es el formato (Video, Display, Search text, Rich media). Es útil cuando hay muchas creatividades con poca historia y se necesita estabilizar rankings.

**Creative family / concepto.** El grupo es una familia de concepto (Concept A, Concept B, Concept C). Se usa en tests creativos y como mecanismo de aprendizaje transferido entre variantes.

**Plataforma / publisher.** El grupo es la plataforma (Meta, Google, TikTok, Programmatic). Aunque el MMM sea por canal, a nivel intra-canal pueden existir dinámicas y saturación efectiva distintas.

### 11.3. Jerarquías anidadas

Una jerarquía completa en MTA puede seguir el patrón:

```
Canal
 └── Plataforma
      └── Formato
           └── Campaña
                └── Creatividad
```

Un esquema conceptual es:
$$
\lambda_{\text{crea}} \sim \operatorname{LogNormal}(\mu_{\text{campaña}},\ \sigma_{\text{crea}}),
$$
y así sucesivamente hacia arriba.

### 11.4. Grupos “blandos”

**Cohortes temporales.** El grupo puede ser una cohorte (campañas lanzadas el mismo mes; HCPs incorporados el mismo trimestre). Esto captura efectos de madurez y cambios estructurales del mercado.

**Clusters aprendidos.** El grupo puede venir de clustering no supervisado (k-means, embeddings), por ejemplo agrupando creatividades por similitud visual o HCPs por comportamiento histórico. Este enfoque es potente, con el coste de mayor riesgo de pérdida de interpretabilidad.

### 11.5. Anti-ejemplos y criterio de decisión

No suelen ser buenos grupos: el ID individual (no agrupa), grupos con un solo elemento, grupos altamente colineales entre sí o grupos sin hipótesis de similitud.

Antes de introducir un grupo conviene verificar: (i) si existe una hipótesis *a priori* de similitud, (ii) si hay escasez de datos a nivel individual, (iii) si el grupo puede mejorar el *cold start* y (iv) si el negocio acepta esa segmentación. Si se cumplen dos o más criterios, suele ser un buen candidato.

### 11.6. Resumen visual (mental)

| Caso      | Grupo típico     | Beneficio         |
| --------- | ---------------- | ----------------- |
| HCP–Brick | Especialidad     | Cold start        |
| HCP–Brick | Región           | Estabilidad       |
| MMM–MTA   | Objective        | Comparabilidad    |
| MMM–MTA   | Formato          | Pooling           |
| MMM–MTA   | Creative family  | Transfer learning |
| Ambos     | Cohorte temporal | Robustez          |

> **Los grupos no son un detalle técnico.
> Son donde introduces conocimiento del negocio en el modelo.**

Como siguiente paso, es habitual escribir un modelo bayesiano completo con 2–3 niveles de grupos, comparar qué grupos valen la pena frente a cuáles no, o traducir un EM actual a una versión jerárquica mínima.

---

## 12. Jerarquía canal → creatividad: atribución a creatividad

### 12.1. Qué significa “atribuir a creatividad” en un modelo jerárquico

Un modelo jerárquico puede producir, en particular, una atribución directa por creatividad:
$$
\hat z_{\text{creatividad},t,g}.
$$

Esa atribución queda regularizada y condicionada por toda la jerarquía (canal → plataforma → formato → campaña → creatividad).

### 12.2. Formulación a nivel de modelo

Considérese la jerarquía:

```
Canal (m)
 └── Plataforma (p)
      └── Formato (f)
           └── Campaña (k)
                └── Creatividad (c)
```

Una parametrización ilustrativa de productividad a nivel creatividad es:
$$
\lambda_c \sim \operatorname{LogNormal}(\mu_k,\ \sigma_c),
$$
y recursivamente:
$$
\mu_k \sim \operatorname{LogNormal}(\mu_f,\ \sigma_k),
$$
$$
\mu_f \sim \operatorname{LogNormal}(\mu_p,\ \sigma_f),
$$
$$
\mu_p \sim \operatorname{LogNormal}(\mu_m,\ \sigma_p).
$$

Cada creatividad tiene su propio $\lambda_c$, pero con *partial pooling*: con pocos datos se aproxima a su campaña; con muchos datos se separa.

### 12.3. Atribución final

En el E-step (o en el posterior predictivo bayesiano), para cada unidad agregada $(m,t,g)$:
$$
\hat z_{c,t,g}
=
C_{m,t,g}
\cdot
\frac{\lambda_c \cdot w_{c,t,g}}
{\sum_{c' \in m} \lambda_{c'} \cdot w_{c',t,g}}.
$$

La unidad final de atribución es la creatividad, pero la estimación de $\lambda_c$ no es independiente: hereda información de toda la jerarquía.

### 12.4. Interpretación y límites

Este resultado no implica identificación causal propia por creatividad, ni permite comparar creatividades de canales distintos “en bruto”, ni implica que una creatividad nueva tenga un $\lambda$ completamente libre. En cambio, sí habilita ranking estable de creatividades dentro de su contexto, control del ruido extremo y gestión de *cold start*.

### 12.5. Comparación con enfoques no jerárquicos

| Enfoque                 | ¿Atribuye a creatividad? | Estabilidad | Cold start |
| ----------------------- | ------------------------ | ----------- | ---------- |
| Heurístico (share imps) | Sí                       | Baja        | No         |
| EM plano                | Sí                       | Media       | No         |
| Bayes jerárquico        | Sí                       | Alta        | Sí         |

La diferencia no es si se atribuye, sino cómo de confiable es esa atribución.

### 12.6. Frase de negocio

> “Sí, atribuimos a creatividad,
> pero la creatividad no compite sola:
> compite dentro de su campaña y formato,
> y el modelo lo tiene en cuenta.”

### 12.7. Regla de diseño

> **Atribuye al nivel más bajo
> para el que tengas señal suficiente
> o pooling jerárquico adecuado.**

Cuando no se cumpla, se baja el nivel (campaña) o se refuerza la jerarquía.

### 12.8. Conclusión

* Un modelo jerárquico canal → creatividad atribuye directamente a creatividad.
* Esa atribución es regularizada, estable y consistente con MMM.
* La atribución no convierte el resultado en causal.

Como siguiente paso natural, se puede dibujar un diagrama completo del modelo generativo jerárquico, escribir pseudocódigo PyMC/NumPyro del modelo canal→creatividad o discutir cuándo no conviene bajar hasta creatividad.

## Resumen

* Un BHM infiere $p(\theta, z \mid y)$ y produce distribuciones posteriores (no solo estimaciones puntuales), habilitando *shrinkage* e intervalos creíbles.
* El *likelihood* base es conceptualmente el mismo que en EM; la diferencia clave aparece en la jerarquía de productividades y en los priors/hyperpriors.
* Las variables latentes $z$ pueden integrarse (lo más común en producción) o muestrearse explícitamente (más literal, pero menos escalable).
* La inferencia suele hacerse con MCMC (preciso, lento) o VI (aproximada, más rápida), según necesidades de escala.
* Los grupos y jerarquías introducen *partial pooling* y controlan *cold start*; definen cómo se comparte información entre entidades.
* Una jerarquía canal → creatividad permite atribución a creatividad, de forma regularizada y no causal.



