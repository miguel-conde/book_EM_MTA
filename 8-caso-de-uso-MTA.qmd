
antes de pasar  al cap√≠tulo 8 me gustar√≠a aplicar EM a otro caso de uso: 

- Tenemos un MMM en granularidad tiempo (semanal, diaria) o tiempo (semanal, diaria) x geo
- Por lo tanto, tenemos por medio la evolucion tiempo o tiempo x geo de su contribuci√≥n
- Queremos repartir las contribuciones a niveles inferiores: por ejemplo campa√±as o creatividades o los que t√∫ quieras considerar. O sea, queremos hacer Multi Touch Attribution (MTA)
- A resolver: aplicar EM para repartir como hemos dicho las contribuciones de los medios
- Para m√°s adelante: en MTA suelen quererse las atribuciones con granularidades temporales mucho mayores (horarias, por ejemplo). Quedar√≠a ver c√≥mo resolver eso

Necesitas algo m√°s antes de empezar? Podr√≠a ser un nuevo cap√≠tulo que se proponga como ejercicio a resolver aunque se proporcionesn las soluciones

***

No necesito nada m√°s para empezar ‚Äî tu planteamiento es suficientemente concreto. S√≠: lo podemos tratar como un **cap√≠tulo extra / ejercicio guiado** (con soluci√≥n), porque es el mismo patr√≥n ‚Äúagregado ‚Üí desagregado‚Äù pero ahora en **tiempo (y quiz√° geo)** y con ‚Äúcomponentes‚Äù tipo **campa√±a/creatividad**.

A continuaci√≥n te propongo el **Cap√≠tulo 8 (alternativo)** como ejercicio resuelto: **EM para desagregar contribuciones de MMM a MTA**.

---

# Cap√≠tulo extra ‚Äî EM para repartir contribuciones de MMM a campa√±as/creatividades (MTA)

## 0) Qu√© es observado y qu√© es latente

### Observado (sale del MMM)

Tienes para cada periodo (y opcionalmente geo):

* (t \in {1,\dots,T}) (semana/d√≠a)
* (g \in {1,\dots,G}) (geo) opcional

Y del MMM obtienes contribuciones por canal/medio:

* (C_{m,t}) o (C_{m,t,g}): contribuci√≥n del **medio/canal** (m) en ese corte.

> Nota: esto puede ser ‚Äúincremental contribution‚Äù del MMM o ‚Äúattributed contribution‚Äù seg√∫n el modelo. EM solo lo toma como ‚Äútotal a repartir‚Äù.

### Objetivo

Repartir esa contribuci√≥n de cada medio (m) hacia unidades inferiores:

* campa√±as (k), creatividades, adsets, publishers‚Ä¶ (lo que definas)

### Latente

* (z_{m,k,t}) (o (z_{m,k,t,g})): contribuci√≥n del medio (m) en (t) asignada a campa√±a/crea (k)

Restricci√≥n dura:
$$
\sum_{k\in \mathcal{K}_m} z_{m,k,t} = C_{m,t}
\quad (\text{o } \sum_k z_{m,k,t,g}=C_{m,t,g})
$$

---

## 1) Modelo generativo base (an√°logamente al HCP‚ÄìBrick)

La analog√≠a es directa:

| HCP‚ÄìBrick            | MMM‚ÜíMTA                                                   |
| -------------------- | --------------------------------------------------------- |
| Brick                | (medio (m), tiempo (t), geo (g))                          |
| HCP                  | campa√±a/creatividad (k) dentro del medio                  |
| ventas (y_b)         | contribuci√≥n (C_{m,t,g})                                  |
| exposici√≥n (w_{h,b}) | se√±ales a nivel campa√±a: spend, impressions, clicks, etc. |

### Exposici√≥n / evidencia por campa√±a

Define features o exposici√≥n para cada campa√±a:

* (w_{m,k,t,g}) = spend (o impresiones) de la campa√±a (k) del medio (m) en (t,g)
* y opcionalmente features (X_{m,k}) (tipo campa√±a, objetivo, formato‚Ä¶)

### Productividad latente por campa√±a dentro del medio

Caso simple (sin covariables a√∫n):

* $\lambda_{m,k} > 0$ (tasa/productividad relativa de campa√±a $(k)$ dentro de medio $(m)$)

Modelo Poisson (para ‚Äúunidades de contribuci√≥n‚Äù):
$$
z_{m,k,t,g} \sim \text{Poisson}(\lambda_{m,k} \cdot w_{m,k,t,g})
$$
y observamos:
$$
C_{m,t,g}=\sum_k z_{m,k,t,g}
$$

Si (C) es continua (euros), puedes usar Gamma (m√°s abajo).

---

## 2) EM expl√≠cito en este contexto (soluci√≥n)

### E-step: repartir (C_{m,t,g}) dentro de cada (m,t,g)

Define:
$$
\mu_{m,k,t,g}^{(r)} = \lambda_{m,k}^{(r)} \cdot w_{m,k,t,g}
$$
$$
p_{m,k,t,g}^{(r)}=
\frac{\mu_{m,k,t,g}^{(r)}}{\sum_{k'}\mu_{m,k',t,g}^{(r)}}
$$

Entonces:
$$
\boxed{
\mathbb{E}[z_{m,k,t,g}\mid C_{m,t,g},\lambda^{(r)}]
=
C_{m,t,g} \cdot p_{m,k,t,g}^{(r)}
}
$$

Interpretaci√≥n:

* dentro de cada medio-tiempo-geo, la campa√±a se lleva m√°s contribuci√≥n si tiene:

  * m√°s exposici√≥n (w) y/o
  * m√°s productividad ($\lambda$).

### M-step: actualizar $\lambda_{m,k}$

Acumulas:
$$
\tilde z_{m,k}=\sum_{t,g}\mathbb{E}[z_{m,k,t,g}]
\quad,\quad
\tilde w_{m,k}=\sum_{t,g} w_{m,k,t,g}
$$

MLE tipo Poisson:
$$
\boxed{
\lambda_{m,k}^{(r+1)} = \frac{\tilde z_{m,k}}{\tilde w_{m,k}}
}
$$

Eso ya es EM completo (sin covariables).

---

## 3) Versi√≥n ‚Äúrealista‚Äù: covariables + regularizaci√≥n

Como antes:
$$
\lambda_{m,k}=\exp(X_{m,k}\beta_m)
$$

* $\beta_m$ puede ser por medio, o compartido

M-step se vuelve un **Poisson GLM con offset**:

* response: (\tilde z_{m,k})
* offset: (\log \tilde w_{m,k})
* regularizaci√≥n ridge/lasso para estabilidad

---

## 4) Caso euros (contribuciones continuas)

Si $C_{m,t,g}$ es continua (moneda), Gamma suele funcionar bien:

$$
z_{m,k,t,g} \sim \text{Gamma}(k,\ \theta_{m,k} w_{m,k,t,g})
$$
con $\theta_{m,k}=\exp(X\beta)$

En muchas parametrizaciones razonables, el reparto del E-step queda (muy similar):
$$
\mathbb{E}[z_{m,k,t,g}\mid C_{m,t,g}]
\approx
C_{m,t,g}\cdot
\frac{\theta_{m,k} w_{m,k,t,g}}{\sum_{k'}\theta_{m,k'} w_{m,k',t,g}}
$$
y el M-step es Gamma-GLM (log link) + regularizaci√≥n.

---

## 5) Qu√© est√°s aprendiendo realmente (y l√≠mites)

Este EM aprende **productividad relativa intra-medio** de campa√±as/creas **consistente con**:

* la serie temporal (y geo) de contribuci√≥n total del MMM
* el patr√≥n de exposici√≥n de campa√±as (spend/imp/clicks)

**No** est√° recuperando ‚Äúverdad causal por campa√±a‚Äù si:

* el MMM no est√° bien identificado por canal
* hay campa√±as altamente colineales dentro del medio
* falta se√±al (w) (o est√° muy ruidosa)

Pero como ‚Äúdesagregador coherente‚Äù del MMM, funciona muy bien.

---

## 6) Lo de ‚Äúgranularidad horaria‚Äù en MTA (para m√°s adelante)

Tu comentario es clave: MMM suele estar en semanal/d√≠a; MTA a veces se quiere a hora/minuto.

Hay 3 rutas t√≠picas:

1. **Downscaling con modelo de intensidad**
   Aprendes un ‚Äúperfil intrad√≠a‚Äù (q(h \mid k,g)) con logs de delivery (imp/click/spend horario) y repartes:
   [
   z_{m,k,t,g,h} = z_{m,k,t,g}\cdot q(h\mid k,g)
   ]
   Esto es determinista o con EM a dos niveles.

2. **Estado-espacio / smoothing temporal**
   Tratas (\lambda_{m,k,t}) como proceso (random walk) y haces inferencia (Kalman/VI).
   √ötil si quieres que productividades var√≠en por hora.

3. **Modelo unificado a alta frecuencia**
   Solo si tienes outcomes y gasto a esa frecuencia (caro y con mucho ruido).

---

# Ejercicio propuesto (con soluci√≥n)

**Ejercicio:** Implementa EM para un solo medio (m) con:

* (C_t) semanal
* campa√±as (k=1..K)
* exposici√≥n (w_{k,t}) = spend
  y estima $\lambda_k$ + $z_{k,t}$.

**Soluci√≥n:** las ecuaciones de arriba (E-step/M-step) y luego extender a covariables con GLM.

---

## ¬øQuieres que lo aterricemos ya en c√≥digo?

Puedo darte un notebook muy parecido al del HCP‚ÄìBrick pero con:

* input: `C_{m,t,g}` (del MMM) + `w_{m,k,t,g}` (spend/imp/click)
* output: `zhat_{m,k,t,g}` y productividades por campa√±a

Y con dos modos:

* ‚Äúsin covariables‚Äù (updates cerrados)
* ‚Äúcon covariables‚Äù (M-step con IRLS + ridge)

Si lo hacemos, asumir√© por defecto:

* contribuci√≥n (C) continua pero **no negativa**
* exposici√≥n = spend (>=0), con smoothing cuando hay ceros

Dime solo si quieres que empecemos por:

1. **1 medio, sin geo** (m√°s simple), o
2. **1 medio, con geo**, o
3. **multi-medio** (mismo framework, un loop por medio).

***

de acuerdo. pero como exposici√≥n no quiero spend sino impresiones, grps o similares. Como suponemos que vienen de un mmm incremental (causal), debemos reflejar tambi√©n el uso de transformaciones adstock + saturaci√≥n. Antes de empezar a generar el notebook:

1) Si el mmm es incremental (causal) el reparto MTA ¬øtambi√©n lo es?
2) Prop√≥n como insertar en la solucion el tema de las transformaciones

***

Genial: si quieres usar **impresiones/GRPs** y adem√°s respetar **adstock + saturaci√≥n** (como en MMM), eso cambia el ‚Äúqu√© significa exposici√≥n‚Äù en el EM, pero el framework encaja muy bien.

Voy por tus 2 preguntas.

---

## 1) Si el MMM es incremental (causal), ¬øel reparto MTA tambi√©n lo es?

**Depende de qu√© entiendas por ‚Äúcausal‚Äù a nivel campa√±a**, pero la respuesta operativa es:

* **El total que repartes (por canal/medio y por (t), (g)) s√≠ es incremental/causal** *si tu MMM lo es*.
* **El reparto dentro del canal (campa√±as/creas)** **no es autom√°ticamente causal** a menos que tengas **identificaci√≥n causal intra-canal**.

### Por qu√©

El MMM ‚Äúincremental‚Äù te identifica algo como:
$$
C_{m,t,g}^{inc} = f(\text{inputs del canal }m) - f(\text{contrafactual sin canal }m)
$$
Eso es causal a nivel canal (bajo supuestos).

Pero cuando lo repartes entre campa√±as, normalmente est√°s usando:

* se√±ales de delivery (impresiones/GRPs, targeting, timing)
* y un modelo de ‚Äúpropensi√≥n‚Äù / ‚Äúintensidad‚Äù
  para decidir shares.

Eso da una atribuci√≥n **coherente** con el incremental del canal, pero **no demuestra** que ‚Äúesa campa√±a‚Äù sea incremental vs otra, porque dentro del canal puede haber:

* colinealidad fuerte (campa√±as corren a la vez)
* selecci√≥n/endogeneidad (las campa√±as se activan cuando se espera demanda)
* distinta mezcla de audiencias

### C√≥mo s√≠ hacerlo ‚Äúm√°s causal‚Äù intra-canal

Necesitar√≠as se√±al de identificaci√≥n adicional, por ejemplo:

* experimentos / geo-lift por campa√±a
* cambios ex√≥genos (holdouts, rotaciones creativas, shocks de supply)
* instrumentos o reglas de asignaci√≥n
* o un modelo jer√°rquico que incorpore ‚Äúpriors causales‚Äù basados en pruebas

üìå Conclusi√≥n clara:

> **MTA por EM puede conservar el ‚Äúincremental total‚Äù del MMM**, pero el **split intra-canal es principalmente model-based attribution**, no causal garantizado.

---

## 2) C√≥mo insertar adstock + saturaci√≥n en la soluci√≥n EM (con impresiones/GRPs)

La forma limpia es: **no usar exposici√≥n cruda (w)**, sino la **exposici√≥n efectiva** tal y como MMM la usa para generar contribuci√≥n.

### En MMM t√≠pico

Para una subentidad (k) (campa√±a/crea) del canal (m), tienes una se√±al ‚Äúraw‚Äù:

* (x_{m,k,t,g}): impresiones / GRPs / TRPs (no spend)

MMM aplica transformaciones:

1. **Adstock** (carryover):
   $$
   a_{m,k,t,g} = \text{Adstock}(x_{m,k,\cdot,g}; \theta_m)
   $$
   (p. ej. geom√©trico con decay $\theta_m$, o Weibull)

2. **Saturaci√≥n** (rendimientos decrecientes):
   $$
   s_{m,k,t,g} = \text{Sat}(a_{m,k,t,g}; \phi_m)
   $$
   (p. ej. Hill / logistic)

Y la contribuci√≥n incremental del canal suele ser algo como:
$$
C_{m,t,g}^{inc} \approx \beta_m \sum_k s_{m,k,t,g}
$$
(si el MMM no tiene campa√±as expl√≠citas, esto es una descomposici√≥n plausible)

---

### C√≥mo meter esto en EM (dos opciones)

#### ‚úÖ Opci√≥n A (recomendada): EM reparte usando **exposici√≥n efectiva MMM-consistente**

Define la exposici√≥n del EM como:
$$
w_{m,k,t,g} := s_{m,k,t,g}
$$
(es decir, **ya adstockeada y saturada**)

Entonces el E-step (shares) queda:
$$
\hat z_{m,k,t,g}
=
C_{m,t,g}^{inc}\cdot
\frac{\lambda_{m,k} \cdot s_{m,k,t,g}}{\sum_{k'} \lambda_{m,k'} \cdot s_{m,k',t,g}}
$$

Ventajas:

* Mantienes exactamente la l√≥gica MMM (carryover + diminishing returns)
* Evitas atribuir m√°s a campa√±as solo por impresiones brutas si est√°n saturadas
* Muy estable y f√°cil de explicar

Qu√© se aprende:

* (\lambda_{m,k}) = ‚Äúeficiencia relativa‚Äù intra-canal (sobre se√±al efectiva)

D√≥nde pones par√°metros de adstock/sat:

* Los tomas del MMM (fijos) o los fijas por canal.

#### Opci√≥n B: EM tambi√©n aprende algunos par√°metros de transformaci√≥n

Puedes extender par√°metros (\theta_m,\phi_m) al set de par√°metros y alternar:

* E-step: imputar (z)
* M-step: actualizar $\beta$ y quiz√°s $\theta,\phi$

Pero aqu√≠ hay un problema pr√°ctico:

* adstock/saturaci√≥n + shares suelen estar **muy no convexos**
* identificabilidad d√©bil (especialmente intra-canal)
* entrenamiento m√°s fr√°gil (necesitar√≠as constraints/priors fuertes)

üìå Para empezar y para producci√≥n, casi siempre:

> **usar (\theta_m,\phi_m) del MMM (fijos) y aprender solo el reparto intra-canal**.

---

### ¬øY si el MMM est√° a nivel canal y no tienes series por campa√±a?

Entonces haces ‚Äútop-down‚Äù:

* Construyes (s_{m,k,t,g}) a partir de delivery de campa√±a (imps/GRPs) usando los mismos (\theta_m,\phi_m)
* Y repartes (C_{m,t,g}^{inc}) con la f√≥rmula anterior

Esto es exactamente lo que quieres.

---

## Recomendaci√≥n final antes del notebook (sin pedirte datos extra)

Para el notebook te propongo este dise√±o:

* Inputs mock:

  * (C_{t}) o (C_{t,g}): contrib incremental por canal (observado)
  * (x_{k,t,g}): impresiones/GRPs por campa√±a (observado)
* Transformaciones:

  * adstock geom√©trico por canal
  * saturaci√≥n Hill por canal
* EM:

  * E-step usando (w=s(x))
  * M-step estimando (\lambda_k) (cerrado) o (\lambda_k=\exp(X_k\beta)) (GLM)

Y a√±adimos secci√≥n ‚Äúm√°s adelante‚Äù:

* desagregaci√≥n a horas via perfil intrad√≠a usando delivery horario + conservaci√≥n de masa

---

## Checkpoint

Si est√°s OK con esto:

* **El total es causal (del MMM), el split intra-canal es attribution model-based**.
* Usamos **adstock+saturaci√≥n para construir (w)** y EM reparte sobre esa se√±al efectiva.

Dime y genero el notebook del caso MMM‚ÜíMTA con mock data (impresiones/GRPs + transforms).

***

adelante, genera el notebook

***

Listo ‚Äî aqu√≠ tienes el notebook del caso **MMM incremental ‚Üí MTA (campa√±as/creas)** usando **impresiones/GRPs** como exposici√≥n y respetando **adstock + saturaci√≥n (Hill)** en el reparto con EM.

[Download the notebook](sandbox:/mnt/data/em_mmm_to_mta_adstock_saturation.ipynb)

Incluye:

* mock data con **tiempo x geo**
* transformaciones **adstock geom√©trico + Hill**
* generaci√≥n de **contribuci√≥n incremental** por medio (como salida del MMM)
* **EM cerrado** (sin covariables) para estimar productividades intra-medio (\lambda_{m,k}) y atribuciones (\hat z_{m,k,t,g})
* checks: conservaci√≥n de masa (\sum_k \hat z = C) y evaluaci√≥n vs ground truth

Cuando lo ejecutes, si quieres, lo siguiente es extender el M-step a **(\lambda=\exp(X\beta))** (regularizaci√≥n, pooling por tipo de campa√±a/crea), igual que en el HCP‚ÄìBrick.

***

que covariables has usado (me interesan estos ejemplos para tener referencias

***

Muy buena pregunta ‚Äî y adem√°s importante para usar esto como **referencia reusable** üëç
Te explico **exactamente qu√© covariables he usado**, **d√≥nde**, y **por qu√©**, y luego te propongo **sets de covariables t√≠picos** que s√≠ usar√≠as en producci√≥n.

---

# Qu√© covariables he usado en el notebook (y para qu√©)

## 1Ô∏è‚É£ Covariables **expl√≠citas** en el notebook

### ‚úÖ **A nivel campa√±a (metadata)**

En `campaign_df` he creado **metadata categ√≥rica**, pero **NO la he usado a√∫n en el modelo EM** (est√° preparada para el siguiente paso):

```python
campaign_rows.append({
    "medium": m,
    "campaign": f"{m}_C{k+1}",
    "creative_family": rng.choice(["A", "B", "C"]),
    "objective": rng.choice(["Awareness", "Consideration", "Conversion"]),
})
```

Estas columnas existen como **ejemplo de covariables potenciales**, pero en este notebook:

* ‚ùå **no entran en (\lambda_{m,k})**
* ‚úîÔ∏è sirven como **plantilla conceptual** para el siguiente cap√≠tulo:
  [
  \lambda_{m,k} = \exp(X_{m,k}\beta_m)
  ]

üëâ Es decir: **las he definido, pero no las he activado todav√≠a**.

---

### ‚úÖ **A nivel tiempo y geo (impl√≠citas, no param√©tricas)**

Estas no entran como regresores, pero **s√≠ afectan al reparto v√≠a la exposici√≥n efectiva**:

#### a) **Tiempo (t)**

* Estacionalidad:

```python
time_season = 1.0 + sinusoides(...)
```

* Adstock aplicado **a lo largo del tiempo**
* Saturaci√≥n dependiente del hist√≥rico

üìå El tiempo entra **no como feature**, sino como **estructura din√°mica** en `w_{m,k,t,g}`.

---

#### b) **Geo**

* `geo_effect` multiplicativo
* Variabilidad de delivery por geo

üìå Geo tampoco entra como covariable param√©trica, pero **modula la exposici√≥n efectiva**.

---

## 2Ô∏è‚É£ La ‚Äúcovariable clave‚Äù realmente usada: exposici√≥n efectiva

Aunque no parezca una covariable tradicional, **esto es lo m√°s importante del notebook**:

### üîë Exposici√≥n usada en EM

$$
w_{m,k,t,g} = s_{m,k,t,g}
= \text{Hill}(\text{Adstock}(x_{m,k,t,g}))
$$

Donde:

* (x): impresiones / GRPs
* Adstock: memoria temporal
* Saturaci√≥n: rendimientos decrecientes

üìå En la pr√°ctica:

> **la mayor parte de la se√±al explicativa est√° en esta transformaci√≥n**, no en (X\beta).

---

## 3Ô∏è‚É£ Qu√© **NO** he usado todav√≠a (a prop√≥sito)

No he usado a√∫n:

* ‚ùå Regresi√≥n Poisson / Gamma en el M-step
* ‚ùå (\lambda_{m,k} = \exp(X\beta))
* ‚ùå Regularizaci√≥n
* ‚ùå Pooling entre campa√±as similares

Esto es deliberado:

* primero dejar claro el **EM ‚Äúpuro‚Äù**
* luego meter covariables como **extensi√≥n controlada**

---

# Sets de covariables recomendados (para referencia real)

Ahora s√≠, lo que te interesa como **cat√°logo de ejemplos** üëá

---

## A) Covariables t√≠picas **a nivel campa√±a / creatividad**

Estas ir√≠an en (X_{m,k}):

### üîπ Creatividad / formato

* tipo de formato (video, display, search text)
* duraci√≥n (6s / 15s / 30s)
* tama√±o
* orientaci√≥n (vertical/horizontal)
* family / concept creativo

### üîπ Objetivo

* awareness / consideration / conversion
* upper vs lower funnel
* always-on vs tactical

### üîπ Audiencia / targeting

* prospecting vs retargeting
* broad vs custom
* socio-demo bucket
* lookalike depth

üëâ Uso t√≠pico:

```text
lambda_{m,k} = exp(
  Œ≤0
+ Œ≤1 * is_video
+ Œ≤2 * is_conversion
+ Œ≤3 * retargeting
+ Œ≤4 * creative_family_B
)
```

---

## B) Covariables **de historial / madurez**

(no dependientes de t)

* antig√ºedad de la campa√±a
* n¬∫ de flights pasados
* frecuencia hist√≥rica media
* % tiempo activa

Sirven para:

* regularizar campa√±as nuevas
* evitar que EM sobre-asigne ruido

---

## C) Covariables **interacci√≥n con exposici√≥n**

(avanzado, pero muy potente)

Ejemplo:

* creatividades saturan antes que otras
* distintos decays por formato

Puedes modelar:
$$
\lambda_{m,k} = \exp(X_k \beta)
\quad\text{y/o}\quad
\gamma_{m,k} = \exp(Z_k \delta)
$$

y usar $\gamma$ para **modular la saturaci√≥n** (cap√≠tulo avanzado).

---

## D) Covariables **a nivel medio (shared priors)**

Para evitar sobreajuste:

* (\beta_m \sim \mathcal N(\beta_{global}, \Sigma))

Esto es:

* **pooling jer√°rquico**
* muy √∫til cuando hay muchos medios con pocas campa√±as

---

# C√≥mo se ver√≠a el siguiente paso (conceptual)

En el siguiente notebook, cambiar√≠amos solo el M-step:

Antes:
$$
\lambda_{m,k} = \frac{\sum_{t,g} \hat z_{m,k,t,g}}{\sum_{t,g} w_{m,k,t,g}}
$$

Despu√©s:
$$
\lambda_{m,k} = \exp(X_{m,k}\beta_m)
$$

y el M-step ser√≠a:

* **Poisson o Gamma GLM**
* response: (\tilde z_{m,k})
* offset: (\log \tilde w_{m,k})
* ridge / lasso

---

## Resumen corto (para llevarte)

* ‚úîÔ∏è **Usado realmente**:

  * exposici√≥n efectiva = adstock + saturaci√≥n
  * tiempo y geo entran estructuralmente
* ‚úîÔ∏è **Definido pero no usado a√∫n**:

  * `creative_family`, `objective` (ejemplos de (X))
* ‚ùå **A√∫n no**:

  * GLM / regularizaci√≥n / pooling

Si quieres, el pr√≥ximo cap√≠tulo puede ser exactamente:

> **‚ÄúCap√≠tulo siguiente ‚Äî EM + covariables en MMM‚ÜíMTA (GLM + regularizaci√≥n)‚Äù**

y ah√≠ usamos **esas covariables concretas** como referencia industrial.

***

Creo que no entiendo bien el concepto $\omega_{bh}$, exposici√≥n al brick ({0,1}) o peso en el brick ([0,1])


***

Muy buena pregunta ‚Äî y es **clave** para entender todo el modelo.
La confusi√≥n es totalmente normal porque **(\omega_{b,h})** (o (w_{h,b})) **no es una sola cosa**, sino un **concepto** que puede instanciarse de varias formas coherentes.

Voy paso a paso y al final te dejo una **regla mental** para no perderte.

---

# Qu√© es realmente (\omega_{b,h})

En todos los ejemplos (HCP‚ÄìBrick, MMM‚ÜíMTA),
$$
\omega_{b,h} \quad \text{(o } w_{h,b}\text{)}
$$
significa:

> **la intensidad de exposici√≥n / elegibilidad / oportunidad**
> que tiene la unidad (h) para generar contribuci√≥n dentro del agregado (b)

No es ‚Äúprobabilidad‚Äù, no es ‚Äúshare‚Äù por s√≠ sola, y **no tiene por qu√© sumar 1**.

---

# Las tres interpretaciones v√°lidas de (\omega_{b,h})

## 1Ô∏è‚É£ Exposici√≥n binaria: ({0,1}) (la m√°s simple)

### Definici√≥n

$$
\omega_{b,h} =
\begin{cases}
1 & \text{si } h \text{ pertenece al brick } b \\
0 & \text{si no}
\end{cases}
$$

### Ejemplo

* HCP‚ÄìBrick:

  * el HCP trabaja en ese brick ‚Üí 1
  * no trabaja ‚Üí 0

### Qu√© implica el modelo

$$
z_{h,b} \sim \text{Poisson}(\lambda_h)
$$

üìå Aqu√≠ **toda la diferenciaci√≥n** viene de $\lambda_h$.

### Cu√°ndo usarlo

* Ejemplo did√°ctico
* No tienes info adicional
* Quieres entender EM ‚Äúen limpio‚Äù

‚ö†Ô∏è Limitaci√≥n: poco realista.

---

## 2Ô∏è‚É£ Exposici√≥n como **intensidad** ([0, +\infty)) (la m√°s habitual)

### Definici√≥n

$$
\omega_{b,h} = \text{cantidad de oportunidad}
$$

Ejemplos:

* n¬∫ de visitas del HCP al brick
* n¬∫ de m√©dicos en ese brick
* impresiones / GRPs de una campa√±a en (t,geo)
* spend (aunque t√∫ ya has dicho que no quieres usarlo)

### Modelo

$$
z_{h,b} \sim \text{Poisson}(\lambda_h \cdot \omega_{b,h})
$$

üìå Interpretaci√≥n:

> a igual productividad $\lambda_h$, m√°s exposici√≥n ‚Üí m√°s contribuci√≥n esperada

### Importante

* $\omega$ **no tiene por qu√© estar normalizada**
* no tiene por qu√© sumar 1 por brick
* puede ser grande (1000 imps) o peque√±a (0.2 GRPs)

---

## 3Ô∏è‚É£ Peso normalizado ([0,1]) (caso especial, NO obligatorio)

A veces se define:
$$
\tilde\omega_{b,h} = \frac{\omega_{b,h}}{\sum_{h'} \omega_{b,h'}}
$$

Esto **no cambia el E-step**, porque en el E-step siempre aparece el cociente:

$$
\frac{\lambda_h \omega_{b,h}}{\sum_{h'} \lambda_{h'} \omega_{b,h'}}
$$

Si multiplicas todos los $\omega$ por una constante, **se cancela**.

### Entonces:

* Normalizar o no normalizar **es irrelevante para el reparto**
* S√≠ afecta a la escala de $\lambda_h$ (pero no a los shares)

üìå Por eso ver√°s implementaciones con ([0,1]) y otras con valores brutos.

---

# Entonces‚Ä¶ ¬øqu√© es (\omega_{b,h}) *en tu cabeza*?

La forma correcta de pensarlo es:

> (\omega_{b,h}) = **‚Äúcu√°nto puede contribuir (h) al brick (b), antes de saber si es bueno o malo‚Äù**

Luego:

* (\lambda_h) = *qu√© tan bueno es (h)*
* (\omega_{b,h}) = *cu√°nta oportunidad tiene*

Y EM combina ambos.

---

# Por qu√© **NO** es una probabilidad

Errores comunes:

‚ùå ‚Äú(\omega) es el share dentro del brick‚Äù
‚Üí No. El share sale del **E-step**, no es input.

‚ùå ‚Äú(\omega) debe sumar 1‚Äù
‚Üí No. Solo importa **relativamente** dentro del brick.

‚ùå ‚Äú(\omega) es causal‚Äù
‚Üí No. Es una **se√±al de exposici√≥n**, no de efecto.

---

# Ejemplos concretos en tus dos casos

## HCP‚ÄìBrick

| Interpretaci√≥n | (\omega_{b,h})               |
| -------------- | ---------------------------- |
| m√≠nima         | 1 si est√°, 0 si no           |
| realista       | n¬∫ visitas                   |
| mejor          | visitas √ó tiempo √ó potencial |

---

## MMM ‚Üí MTA

| Se√±al           | (\omega_{m,k,t,g})  |
| --------------- | ------------------- |
| cruda           | impresiones / GRPs  |
| mejor           | adstock(imps)       |
| MMM-consistente | Hill(adstock(imps)) |

üìå En este √∫ltimo:

> (\omega) **ya incorpora** carryover y saturaci√≥n.

---

# Regla mental (la m√°s importante)

> **Si quitas (\lambda_h), (\omega_{b,h}) debe seguir teniendo sentido como ‚Äúoportunidad de generar contribuci√≥n‚Äù**

Si cumple eso, es una buena (\omega).

---

## Cierre

Tu duda es exactamente la correcta, porque:

* muchos papers y c√≥digos **mezclan** estos conceptos sin decirlo
* y parece que (\omega) ‚Äútiene que ser‚Äù una cosa concreta

No:
üëâ **(\omega) es una elecci√≥n de modelado**, y lo importante es que sea:

* no negativa
* interpretable
* coherente con el proceso real

Si quieres, en el siguiente mensaje podemos:

* dibujar el paralelismo exacto HCP‚ÄìBrick ‚Üî MMM‚ÄìMTA con una tabla formal
* o ver qu√© pasa si eliges una (\omega) ‚Äúmala‚Äù (ejemplos de fallo del EM)


***

Si, dibuja el paralelismo exacto HCP‚ÄìBrick ‚Üî MMM‚ÄìMTA con una tabla formal

***

Perfecto. Vamos a hacerlo **formal, exacto y sim√©trico**, para que puedas usarlo como **referencia mental y t√©cnica** en cualquier documento o discusi√≥n.

---

# Paralelismo exacto: **HCP‚ÄìBrick ‚Üî MMM‚ÄìMTA**

Piensa que **es el mismo modelo** con nombres distintos.
La siguiente tabla es **isom√≥rfica**: cada fila es exactamente el mismo objeto estad√≠stico.

---

## üß© Tabla formal de equivalencia

| Concepto estad√≠stico        | HCP‚ÄìBrick                                         | MMM ‚Üí MTA                                                     |
| --------------------------- | ------------------------------------------------- | ------------------------------------------------------------- |
| Unidad agregada (observada) | Brick (b)                                         | (Medio (m), tiempo (t), geo (g))                              |
| Unidad individual (latente) | HCP (h)                                           | Campa√±a / Creatividad (k)                                     |
| Observaci√≥n agregada        | Ventas del brick (y_b)                            | Contribuci√≥n incremental (C_{m,t,g})                          |
| Variable latente            | (z_{h,b}): ventas de (h) en (b)                   | (z_{m,k,t,g}): contribuci√≥n de (k)                            |
| Restricci√≥n dura            | (\sum_h z_{h,b} = y_b)                            | (\sum_k z_{m,k,t,g} = C_{m,t,g})                              |
| Productividad               | (\lambda_h)                                       | (\lambda_{m,k})                                               |
| Exposici√≥n                  | (\omega_{b,h})                                    | (\omega_{m,k,t,g})                                            |
| Exposici√≥n cruda            | pertenencia / visitas                             | impresiones / GRPs                                            |
| Exposici√≥n efectiva         | visitas ponderadas                                | Hill(Adstock(imps))                                           |
| Modelo latente              | (z \sim \text{Poisson}(\lambda \omega))           | (z \sim \text{Poisson/Gamma}(\lambda \omega))                 |
| E-step                      | reparto dentro del brick                          | reparto dentro de (m,t,g)                                     |
| M-step (simple)             | (\lambda_h = \frac{\sum_b \hat z}{\sum_b \omega}) | (\lambda_{m,k} = \frac{\sum_{t,g} \hat z}{\sum_{t,g} \omega}) |
| M-step (con features)       | (\lambda_h=\exp(X_h\beta))                        | (\lambda_{m,k}=\exp(X_{m,k}\beta_m))                          |
| Interpretaci√≥n del output   | atribuci√≥n por HCP                                | atribuci√≥n por campa√±a/crea                                   |
| Naturaleza causal           | ‚ùå (atribuci√≥n)                                    | ‚ùå intra-canal (total s√≠)                                      |

---

## üîÅ Misma ecuaci√≥n central (cambiando nombres)

### HCP‚ÄìBrick

$$
\hat z_{h,b}
=
y_b \cdot
\frac{\lambda_h \cdot \omega_{b,h}}{\sum_{h'} \lambda_{h'} \cdot \omega_{b,h'}}
$$

### MMM‚ÄìMTA

$$
\hat z_{m,k,t,g}
=
C_{m,t,g} \cdot
\frac{\lambda_{m,k} \cdot \omega_{m,k,t,g}}{\sum_{k'} \lambda_{m,k'} \cdot \omega_{m,k',t,g}}
$$

üëâ **Es la misma ecuaci√≥n**.

---

## üéØ Interpretaci√≥n sem√°ntica (muy importante)

| S√≠mbolo   | Significado universal                   |
| --------- | --------------------------------------- |
| (z)       | ‚ÄúQui√©n explica cu√°nto del total‚Äù        |
| (y) / (C) | Total observado que **debe** explicarse |
| (\lambda) | Eficiencia / productividad relativa     |
| (\omega)  | Oportunidad / intensidad de exposici√≥n  |
| E-step    | reparto consistente                     |
| M-step    | aprendizaje de productividades          |

---

## üß† Qu√© cambia *realmente* entre los casos

### En HCP‚ÄìBrick

* (\omega_{b,h}) suele ser **simple**

  * 0/1
  * visitas
* el problema es **espacial**

### En MMM‚ÄìMTA

* (\omega_{m,k,t,g}) es **modelada**

  * adstock
  * saturaci√≥n
* el problema es **temporal + causal top-down**

Pero matem√°ticamente:

> **son el mismo problema de inferencia con variables latentes y suma fija**.

---

## ‚ö†Ô∏è Errores comunes que esta tabla evita

‚ùå ‚ÄúEn MMM‚ÄìMTA es otro modelo‚Äù
‚Üí No: es el mismo EM con otra sem√°ntica.

‚ùå ‚Äú(\omega) debe sumar 1‚Äù
‚Üí No en ninguno de los dos.

‚ùå ‚ÄúSi MMM es causal, MTA tambi√©n‚Äù
‚Üí El total s√≠; el reparto no necesariamente.

---

## üß≠ Regla de oro final

> **Si sabes explicar HCP‚ÄìBrick, sabes explicar MMM‚ÄìMTA.
> Solo cambia qu√© significa (\omega) y qu√© significa el total observado.**

---

Si quieres, el siguiente paso natural ser√≠a:

* **misma tabla pero para ‚Äúcon covariables‚Äù**
* o **ejemplos de malas elecciones de (\omega) y c√≥mo rompen el modelo**
* o **c√≥mo explicar esta tabla a negocio en 3 slides**

T√∫ mandas.

