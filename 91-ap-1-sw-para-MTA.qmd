# Software para MMM → MTA

Este apéndice responde a una pregunta práctica: qué software de libre acceso permite implementar el enfoque discutido en el libro (MMM incremental y su reparto intra-canal con EM, manteniendo adstock y saturación), y qué alternativas resultan razonables en función del objetivo y la madurez del equipo. El ecosistema mezcla ofertas comerciales y repositorios abiertos, con un nivel de claridad desigual.

## Software público para MMM → MTA con adstock, saturación y EM

En el estado actual del ecosistema, no existe un software open-source que haga de forma integrada todo el flujo (MMM incremental y EM intra-canal con adstock/saturación). Sí existen herramientas de MMM muy sólidas y herramientas de MTA (heurístico o probabilístico) que cubren partes del problema. El puente MMM → MTA vía EM suele implementarse como una capa propia (*custom* o *research-grade*), típicamente en un stack híbrido (MMM open-source y una capa EM interna).

## Software de MMM (adstock, saturación e incrementalidad)

Estas piezas están relativamente bien resueltas en open source.

### Meta — Robyn

Robyn (repositorio `facebookexperimental/Robyn`, en R) ofrece implementaciones estándar de adstock (geométrico y Weibull), saturación (Hill) y MMM incremental con regularización, con descomposición por canal y por tiempo. No está diseñado para bajar a campañas/creatividades ni para resolver MTA intra-canal. En la práctica, se considera un estándar de facto open-source para MMM.

### Google — LightweightMMM

LightweightMMM (Python, JAX) es una opción sólida cuando el foco es un MMM bayesiano con cuantificación explícita de incertidumbre. Sus limitaciones habituales aparecen en flexibilidad de descomposición avanzada y, de nuevo, no resuelve MTA.

### Uber — Orbit

Orbit se orienta a modelos de series temporales de tipo causal/estructural. No es un MMM “puro”, pero puede resultar útil para incrementalidad y contrafactuales. No resuelve, por sí mismo, el reparto intra-canal tipo MTA.

## Software de MTA (no MMM-consistente)

En este bloque existe confusión frecuente, porque muchas soluciones MTA operan sin un MMM incremental que las constriña.

### Plataformas MTA clásicas (rule-based o probabilísticas)

Ejemplos típicos incluyen Adobe Attribution IQ, Google Attribution (deprecated/absorbed) y soluciones de mobile como AppsFlyer o Adjust. Para el planteamiento de este libro, presentan tres fricciones: no parten de un MMM incremental, no respetan de forma explícita adstock/saturación y operan a nivel de touchpoints, no a nivel de contribución incremental causal. Por tanto, no son compatibles con el enfoque MMM→MTA descrito aquí.

## Software open-source para EM en attribution

En la práctica, no hay un producto mantenido que implemente EM para attribution con conciencia de MMM.

### Spotify — Luigi attribution models

Existen referencias a repositorios internos o *papers* que usan EM y Poisson, pero no se trata de un producto mantenido ni orientado a MMM.

### Paquetes genéricos

Paquetes como `pomegranate` (mixtures con EM), `hmmlearn` (HMM) o librerías de inferencia probabilística como `pyro` y `numpyro` resuelven piezas genéricas, pero no vienen con los componentes específicos de este libro: adstock, saturación y conservación de masa sobre contribuciones de MMM.

## Práctica industrial: stack híbrido

Un stack realista que se observa en organizaciones maduras separa capas.

### Capa 1 — MMM (off-the-shelf)

Se usa Robyn o LightweightMMM. Como salida, se obtiene $C_{m,t,g}^{inc}$ y, típicamente, parámetros de adstock y saturación por canal.

### Capa 2 — EM intra-canal (custom)

Se implementa una capa específica como la presentada en el libro: EM Poisson/Gamma, construcción de exposición efectiva como `Hill(Adstock(imps))` y reparto top-down bajo conservación de masa.

### Capa 3 — Downscaling temporal (opcional)

Puede añadirse un downscaling temporal (p. ej., perfiles horarios), manteniendo la conservación de masa.

Este conjunto no está empaquetado en ningún OSS hoy.

## Recomendación según objetivo

### Operatividad inmediata

Para una implementación rápida, se puede combinar Robyn como MMM con un MTA heurístico simple (p. ej., share de impresiones adstockeadas). Este camino sacrifica rigor probabilístico.

### Rigor y control

Para una solución consistente con el enfoque del libro, la alternativa habitual es construir una capa propia: MMM con Robyn/LightweightMMM y reparto intra-canal con EM (como el notebook ya existente), incorporando regularización y covariables. Este patrón aparece en organizaciones con equipos de econometría o causal inference (big tech y marketplaces).

### Bayesiano end-to-end

Un enfoque bayesiano end-to-end combina un MMM bayesiano y una atribución bayesiana jerárquica, con herramientas como `numpyro` o `pyro`. Esta opción suele ser más costosa computacionalmente y más difícil de explicar a negocio.

## Por qué no existe un “producto” que haga todo

La ausencia de una solución empaquetada responde a causas estructurales: cada empresa usa definiciones distintas de incrementalidad, modelos MMM con supuestos no equivalentes, granularidades diferentes y restricciones legales (privacy). Además, la atribución intra-canal no es identificable sin supuestos adicionales, y los proveedores tienden a evitar exponer supuestos discutibles. El resultado habitual es un pipeline *custom*.

## Recomendación operativa

Una recomendación coherente con el flujo de este libro consiste en usar Robyn para MMM y mantener una capa EM propia como librería interna. Esto aporta transparencia, control metodológico y extensibilidad a nuevos casos (HCPs, MTA, geo y retail).

Como siguientes pasos posibles, se incluye: definir la arquitectura end-to-end MMM → MTA, extender el EM con covariables (GLM) dentro del notebook, delinear una versión bayesiana conceptual o preparar un checklist de riesgos y *governance* para producción.

## Sobre librerías tipo `sklearn` para EM intra-canal

No existe un equivalente directo en el sentido de “conectar y ejecutar”, como `sklearn.GaussianMixture`. El problema tratado aquí tiene dos rasgos que `sklearn` no cubre: la restricción de conservación de masa por grupo,
$$
\sum_k z_{m,k,t,g} = C_{m,t,g},
$$
y un E-step específico donde las responsabilidades están condicionadas al total agregado (el “brick” en este contexto es $(m,t,g)$). En consecuencia, el problema se acerca más a *data augmentation* con restricciones que a un estimador estándar.

## Componentes reutilizables

Una parte del flujo puede reutilizarse con librerías existentes.

### `statsmodels` para el M-step (GLM)

En la parametrización
$$
\lambda_{m,k}=\exp(X_{m,k}\beta_m),
$$
el M-step es un Poisson/Gamma GLM con offset, y pueden emplearse `statsmodels.api.GLM(..., family=Poisson())` o `statsmodels.api.GLM(..., family=Gamma(link=log))`. Esto evita implementar IRLS a mano y aporta salidas estándar (p. ej., diagnósticos). El E-step sigue siendo específico, pero puede mantenerse como una implementación vectorizada breve.

### Optimización genérica para el M-step

Si no se utiliza `statsmodels`, es habitual ajustar el M-step con `scipy.optimize.minimize` incorporando penalizaciones ridge/lasso y manteniendo el E-step vectorizado.

### Probabilistic programming (si se persigue un enfoque bayesiano)

Herramientas como `PyMC`, `Pyro` o `NumPyro` permiten inferencia (NUTS/VI). Este camino no implementa EM; sustituye EM por inferencia probabilística, con el coste y la complejidad correspondientes.

## Librerías EM existentes y por qué no encajan

`sklearn.mixture.GaussianMixture` implementa EM para mixtures gaussianos sobre datos individuales; no cubre el caso de sumas agregadas con restricción. `pomegranate` cubre mixtures/HMM con EM, pero no incorpora la restricción $\sum z = C$. `hmmlearn` implementa HMM con EM y solo resulta relevante si se introduce una latencia temporal explícita. Estas librerías son una referencia útil de estructura (p. ej., `fit` y `predict_proba`), pero no resuelven el núcleo del problema.

## Recomendación práctica (estilo `sklearn`)

Una solución que suele funcionar en equipos de Data Science es construir un estimador pequeño “sklearn-like” con una API explícita, por ejemplo: `fit(C_df, x_df, campaign_features_df)`, `predict_allocation()` (devuelve $\hat z_{m,k,t,g}$) y `get_params()` (devuelve $\hat\lambda$ o $\hat\beta$). Internamente, el E-step se mantiene en NumPy vectorizado y el M-step se resuelve con `statsmodels.GLM` o IRLS propio con ridge. Este enfoque facilita reproducibilidad, tests (conservación de masa, monotonicidad y estabilidad) e integración con un pipeline MMM.

Un siguiente paso natural es convertir el notebook MMM→MTA en una clase tipo sklearn (`MMM2MTAEM`) con `fit`/`transform`, soportando exposición efectiva mediante adstock y saturación, un modo “closed form” (sin covariables) y un modo “GLM” (con covariables y regularización).
