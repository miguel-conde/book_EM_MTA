# Preface {.unnumbered}

Este libro es una guía **pragmática y end-to-end** para entender y aplicar el algoritmo **Expectation–Maximization (EM)** a un problema recurrente en analytics:

> Tienes un **total agregado** (ventas por brick, contribución incremental por canal, etc.) y necesitas repartirlo a unidades inferiores (HCPs, campañas, creatividades) de forma **coherente, auditable y reproducible**.

La tesis del libro es simple:

- El problema es, de forma natural, un **modelo de variables latentes**.
- El reparto que buscamos es la **esperanza condicional** de esas variables latentes bajo un modelo generativo.
- **EM** es el mecanismo estándar para estimar productividades/eficiencias y obtener un reparto consistente.

## Para quién es

- Data Scientists / Analytics que trabajan con MMM/MTA, CRM, ventas agregadas o asignación de crédito.
- Equipos que necesitan un output **estable** (no una heurística) y defendible ante negocio.

## Lo que este libro SÍ y NO hace

Sí:

- Garantiza conservación de masa: la atribución **cuadra exactamente** con el agregado observado.
- Da un marco probabilístico claro para *credit allocation*.
- Enseña criterios de producción: identificabilidad, regularización, cold start, estabilidad.

No (a propósito):

- No promete causalidad intra-canal por sí misma. Si el total viene de un MMM incremental, el total es “causal”; el **split** intra-canal es un modelo explicativo salvo identificación extra.
- No sustituye experimentos (geo-lift, A/B, etc.).

## Cómo leerlo (ruta recomendada)

1. Capítulos 1–4: marco conceptual + modelo + EM + ejemplo pequeño a mano.
2. Capítulos 5–7: salto a producción (covariables) + mock data + implementación en Python.
3. Capítulo extra (MMM → MTA): cómo reutilizar el mismo patrón para bajar de canal a campañas/creatividades.
4. Capítulos finales: unidades vs euros, pitfalls, cómo explicarlo a negocio, y alternativa bayesiana.

## Rutas de lectura por perfil

### Perfil: liderazgo de marketing (CMO y dirección)

Una ruta corta y orientada a decisión consiste en leer:

1. [Introducción — De agregado a desagregado: HCP–Brick y MMM→MTA](intro.qmd).
2. [Cómo explicar EM + MMM + MTA a negocio en 3 slides](11-explicar-a-negocio.qmd).
3. [Ap-2 — Whitepaper para CXOs (EN)](92-ap-2-doc-CXOs.qmd).
4. [Blog post (CMO)](94-blog_post_CMO.qmd).

### Perfil: Data Science (desarrollo y producción)

Una ruta corta y orientada a implementación consiste en leer:

1. [Modelo probabilístico base (Poisson) y notación](2-modelo-base.qmd).
2. [EM paso a paso: E-step (reparto) y M-step (estimación)](3-EM-paso-a-paso.qmd).
3. [Modelo realista: covariables, regularización y estabilidad](5-modelo-realista.qmd).
4. [Implementación en Python: E-step vectorizado + M-step (GLM con offset)](7-implementacion-python.qmd).
5. [Pitfalls en producción y extensiones](10-pitfalls-y-extensiones.qmd).
6. [Ap-1 — Software para MMM → MTA](91-ap-1-sw-para-MTA.qmd) y [Blog post (Head of Data Science)](95-blog-post-DS.qmd).

## Mapa del contenido

- **Capítulo 1**: plantea el problema como variables latentes y conecta con mixture/credit attribution.
- **Capítulo 2**: formaliza el modelo base (Poisson para unidades; Gamma/Lognormal para euros) y el rol de la exposición.
- **Capítulo 3**: deriva EM paso a paso y fija la interpretación del “share”.
- **Capítulo 4**: ejemplo numérico mínimo (2 bricks, 4 HCPs) para interiorizar la dinámica.
- **Capítulo 5**: modelo realista con covariables: $\lambda_h=\exp(X_h\beta)$, M-step como GLM con offset + regularización.
- **Capítulo 6**: generación de datos mock con ground truth para testear recuperación y estabilidad.
- **Capítulo 7**: implementación completa en Python (E-step vectorizado + M-step IRLS + ridge) y checklist de debugging.
- **Capítulo extra (MMM → MTA)**: aplica EM para repartir contribuciones de MMM a campañas/creatividades por tiempo y geo.
- **Capítulo 8 (Unidades vs Euros)**: guía práctica de elección Poisson vs Gamma/Lognormal y consecuencias en EM.
- **Capítulo 9 (Pitfalls y extensiones)**: identificabilidad, overfitting silencioso, cold start, jerárquico/VI.
- **Capítulo 10 (Explicar a negocio)**: una narrativa defendible en 3 slides + Q&A difícil.
- **Capítulo 12 (Bayesiano)**: cómo se vería un modelo jerárquico, qué cambia y qué ganas (incertidumbre + shrinkage).
- **Apéndices**: software público relevante, documento para CXOs, y nomenclatura de “exposure/offset”.

## Notebooks incluidos

Además del texto, el repositorio incluye dos notebooks end-to-end.

### EM HCP–Brick (Poisson) — End-to-End

El notebook [em_hcp_brick_end_to_end.ipynb](em_hcp_brick_end_to_end.ipynb) muestra un flujo completo para:

- Generar datos mock HCP–brick con *ground truth*.
- Ejecutar EM con E-step vectorizado y M-step como GLM con *offset*.
- Validar conservación de masa y evaluar recuperación.

### MMM → MTA con adstock + saturación

El notebook [em_mmm_to_mta_adstock_saturation.ipynb](em_mmm_to_mta_adstock_saturation.ipynb) muestra un flujo completo para:

- Construir **exposición efectiva MMM-consistente** con adstock + saturación (Hill).
- Repartir contribución incremental $C_{m,t,g}^{inc}$ a campañas dentro de cada medio.
- Validar conservación de masa y comparar contra *ground truth* en datos simulados.
