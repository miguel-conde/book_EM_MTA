Perfecto. Este es **el capÃ­tulo que diferencia a alguien que â€œsabe EMâ€ de alguien que lo puede poner en producciÃ³n**. Voy a ser deliberadamente **pragmÃ¡tico y un poco duro**: esto es criterio de senior.

---

# ğŸ“• CapÃ­tulo 9 â€” **Pitfalls reales y extensiones**

**Criterio de Senior Data Scientist**

---

## 1ï¸âƒ£ Identifiability: el problema que nunca desaparece

### â“ QuÃ© significa aquÃ­

Un modelo es identificable si **los datos contienen suficiente informaciÃ³n** para distinguir los parÃ¡metros.

En EM intra-canal / HCPâ€“Brick:
[
y_b = \sum_h z_{h,b},\quad
z_{h,b} \sim f(\lambda_h \omega_{b,h})
]

ğŸ‘‰ **No todo (\lambda) es identificable**.

---

### ğŸš¨ Casos tÃ­picos de no-identificabilidad

#### a) Colinealidad perfecta en (\omega)

Ejemplo:

* dos campaÃ±as siempre activas juntas
* mismo perfil temporal y geo
* mismas impresiones adstockeadas

Entonces:
[
\lambda_1 \omega_1 + \lambda_2 \omega_2
]
no se puede separar.

ğŸ“Œ **EM â€œeligeâ€ arbitrariamente**.

---

#### b) Escala no identificable

Si multiplicas:

* (\lambda_h \leftarrow c\lambda_h)
* (\omega_{b,h} \leftarrow \omega_{b,h}/c)

ğŸ‘‰ El likelihood no cambia.

ğŸ“Œ SoluciÃ³n:

* fijar escala de (\omega)
* normalizar (\lambda) (media = 1)
* usar offsets explÃ­citos

---

### ğŸ§  Criterio senior

> **Si dos entidades no se diferencian en (\omega) a lo largo del dataset, no esperes que EM las diferencie.**

---

## 2ï¸âƒ£ Overfitting silencioso (el mÃ¡s peligroso)

### QuÃ© lo hace â€œsilenciosoâ€

* El likelihood sube
* Las mÃ©tricas internas mejoran
* El output parece â€œrazonableâ€

Pero:

* el modelo estÃ¡ explicando **ruido**
* los (\lambda) son inestables entre runs

---

### SÃ­ntomas tÃ­picos

* (\lambda) con varianza enorme
* rankings que cambian por seed
* campaÃ±as nuevas â€œgananâ€ sin evidencia
* extrema sensibilidad a un brick

---

### AntÃ­dotos prÃ¡cticos

#### âœ… RegularizaciÃ³n (no opcional)

* ridge / lasso
* o priors normales

#### âœ… Pooling jerÃ¡rquico

[
\lambda_h \sim \text{LogNormal}(\mu_{\text{group}}, \sigma)
]

#### âœ… Tests de estabilidad

* re-fit con bootstrap temporal
* compara rankings

ğŸ“Œ **Si no haces esto, EM miente educadamente.**

---

## 3ï¸âƒ£ Cold start (HCPs / campaÃ±as nuevas)

### El problema

Un HCP o campaÃ±a con:

* poca (\omega)
* pocos bricks
* datos recientes

ğŸ‘‰ EM tiende a:

* asignarles extremos
* o colapsarlos a cero

---

### Soluciones ordenadas por madurez

#### ğŸŸ¢ Nivel 1 â€” HeurÃ­stica

* floor en (\omega)
* shrinkage manual

#### ğŸŸ¡ Nivel 2 â€” Covariables

[
\lambda_h = \exp(X_h \beta)
]

Comparte seÃ±al entre entidades similares.

#### ğŸ”µ Nivel 3 â€” JerÃ¡rquico

[
\beta_h \sim \mathcal N(\beta_{\text{group}}, \Sigma)
]

---

### Regla senior

> **Si tienes cold start, EM sin pooling es mala idea.**

---

## 4ï¸âƒ£ EM vs Bayesian Hierarchical Models (BHM)

### QuÃ© hace EM realmente

* estima **puntos** ((\hat\lambda))
* asume mÃ¡xima verosimilitud
* no propaga incertidumbre

### QuÃ© hace un BHM

* estima **distribuciones**
* hace shrinkage automÃ¡tico
* maneja mejor colas y escasez

---

### ComparaciÃ³n honesta

| Aspecto           | EM         | Bayesian JerÃ¡rquico |
| ----------------- | ---------- | ------------------- |
| Complejidad       | Baja       | Alta                |
| Escalabilidad     | Muy alta   | Media               |
| Interpretabilidad | Alta       | Media               |
| Incertidumbre     | âŒ          | âœ…                   |
| Cold start        | âŒ          | âœ…                   |
| Priors            | ImplÃ­citos | ExplÃ­citos          |
| Debug             | FÃ¡cil      | DifÃ­cil             |

---

### Criterio senior

> **EM es un excelente baseline productivo.
> BHM es para cuando ya sabes exactamente por quÃ© EM falla.**

---

## 5ï¸âƒ£ CuÃ¡ndo pasar a Variational Inference (VI)

### SeÃ±ales claras de que EM ya no basta

#### ğŸš© 1) Mucha jerarquÃ­a

* campaÃ±as dentro de medios
* creatividades dentro de campaÃ±as
* geos dentro de paÃ­ses

EM se vuelve un Frankenstein.

---

#### ğŸš© 2) Incertidumbre importa

* decisiones de inversiÃ³n
* intervalos de confianza
* risk management

---

#### ğŸš© 3) Datos escasos + colas pesadas

* revenue extremo
* pocos puntos por entidad

---

### QuÃ© te da VI

* posteriors aproximados
* shrinkage natural
* control fino de regularizaciÃ³n

### Coste

* diseÃ±o de modelo
* tuning
* tiempo de cÃ³mputo
* dificultad de explicaciÃ³n

ğŸ“Œ **No es un upgrade trivial, es un cambio de paradigma.**

---

## 6ï¸âƒ£ Anti-patterns (cosas que NO hacer)

âŒ â€œEM converge, luego estÃ¡ bienâ€
âŒ â€œMÃ¡s features = mejorâ€
âŒ â€œSi sube el likelihood, es correctoâ€
âŒ â€œUsar Lognormal porque es revenueâ€
âŒ â€œCold start sin poolingâ€

---

## 7ï¸âƒ£ Checklist de senior antes de producciÃ³n

Antes de poner EM en prod, pregÃºntate:

* [ ] Â¿(\omega) distingue realmente a las entidades?
* [ ] Â¿He fijado la escala?
* [ ] Â¿Hay regularizaciÃ³n explÃ­cita?
* [ ] Â¿He probado estabilidad temporal?
* [ ] Â¿Tengo estrategia para cold start?
* [ ] Â¿SÃ© explicar por quÃ© **no** es causal?

Si fallas 2 o mÃ¡s â†’ **no estÃ¡ listo**.

---

## 8ï¸âƒ£ ConclusiÃ³n (criterio real)

> **EM es un bisturÃ­, no un martillo.**
> En manos expertas: preciso, rÃ¡pido, explicable.
> En manos inexpertas: elegante y peligrosamente convincente.

---

## âœ”ï¸ Salida â€” **Criterio de Senior Data Scientist**

* Usa EM cuando:

  * el problema es â€œrepartir un totalâ€
  * tienes buena seÃ±al en (\omega)
  * necesitas algo estable y explicable

* PÃ¡sate a jerÃ¡rquico / VI cuando:

  * hay mucha escasez
  * necesitas incertidumbre
  * el negocio lo exige

---

Si quieres, el siguiente (y Ãºltimo) capÃ­tulo podrÃ­a ser:

* **CapÃ­tulo 10 â€” CÃ³mo explicar EM + MMM + MTA a negocio en 3 slides**,
  o
* **CapÃ­tulo 10 â€” DiseÃ±o de una librerÃ­a interna EM para attribution (API + tests)**
